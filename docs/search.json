[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "BIOL4062/5062 Analysis of Biological Data: Assignment Guide",
    "section": "",
    "text": "Introduction\nWelcome to the assignment guide for BIOL4062/5062: Analysis of Biological Data.\nThis book is designed to walk you through the assignments for this class. It is a resource to help you figure out how to code for your assignments, and bring attention to key questions to ask yourself as you interpret your results, both statistically and biologically. Keep in mind that there are always different ways to get to the right answer with coding. This book is not a monolith, and you do not need to follow it if you don’t want to (more in Assignment Guidelines), but make sure what you are doing is clear and sufficiently analogous to this guide, else you lose marks for being unclear, or running the wrong analyses.\nWithout further ado, let’s get into it!"
  },
  {
    "objectID": "a1a.html#looking-at-the-data",
    "href": "a1a.html#looking-at-the-data",
    "title": "1  Assignment 1a: Principal Components Analysis",
    "section": "1.1 Looking at the Data",
    "text": "1.1 Looking at the Data\nWith any data analysis, step 1 is always to look at your data:\n\n# Load in data\ndata = read.csv('fishcatch.csv')\n\n# View data structure\nhead(data)\n\n  Hauls mackerel bluefin sardine squid limpet\n1     1    1.851   55.60   0.058  6.00 0.0004\n2     2    1.925    1.20   0.252  0.08 0.0027\n3     3    2.506    1.56   0.133  0.06 0.0015\n4     4    1.537   30.00   0.064  9.35 0.0013\n5     5    1.795    0.04   0.086  4.70 0.0022\n6     6    3.371   45.00   0.078  7.66 0.0006\n\ndim(data)\n\n[1] 25  6\n\n\nOur data is a 25 row, 6 column data frame, describing catch of 5 different fisheries species (columns 2-6) caught across 25 hauls (column 1). We want to know if certain species are associated with each other. Lets look a little deeper at the data:\n\n# Generate boxplots\nboxplot(data[,-1]) # Exclude haul\n\n\n\n# look at data distribution\n# par(mfrow = c(3,2)) # 1 column 5 row grid plot\nhist(data$mackerel, breaks = 10)\n\n\n\nhist(data$bluefin, breaks = 10)\n\n\n\nhist(data$sardine, breaks = 10)\n\n\n\nhist(data$squid, breaks = 10)\n\n\n\nhist(data$limpet, breaks = 10)\n\n\n\n\nA few things are immediately obvious from looking at our data:\n1. There are some large outliers\n2. The data scales vary greatly across species\n3. The species all have relatively different distributions, none of which look normal.\nAre these issues? How do we fix them?"
  },
  {
    "objectID": "a1a.html#transformations",
    "href": "a1a.html#transformations",
    "title": "1  Assignment 1a: Principal Components Analysis",
    "section": "1.2 Transformations",
    "text": "1.2 Transformations\nLook back at the PCA lecture. What are potential problems with PCA?\n1. Covariance Matrix PCA requires data to be in the same units\n2. Normality is desirable, but not essential\n3. Precision is desireable, but not essential\n4. Many zeroes in the data\nWe can fix issue 1 by logging our data:\n\n# Create a new data object so we can log the data\ndata_log = data\n\n# Log data\ndata_log[,-1] = log(data_log[,-1]) # Remember to exclude haul\n\nNow that we’ve transformed the data, let’s check for normality again:\n\n# Generate histograms\n# par(mfrow = c(3,2)) # 1 column 5 row grid plot\nhist(data_log$mackerel, breaks = 10)\n\n\n\nhist(data_log$bluefin, breaks = 10)\n\n\n\nhist(data_log$sardine, breaks = 10)\n\n\n\nhist(data_log$squid, breaks = 10)\n\n\n\nhist(data_log$limpet, breaks = 10)\n\n\n\n\nThese look much better. We can also confirm this statistically:\n\n# Generate histograms\nshapiro.test(data_log$mackerel)\n\n\n    Shapiro-Wilk normality test\n\ndata:  data_log$mackerel\nW = 0.9425, p-value = 0.1691\n\nshapiro.test(data_log$bluefin)\n\n\n    Shapiro-Wilk normality test\n\ndata:  data_log$bluefin\nW = 0.98186, p-value = 0.9193\n\nshapiro.test(data_log$sardine)\n\n\n    Shapiro-Wilk normality test\n\ndata:  data_log$sardine\nW = 0.94113, p-value = 0.1572\n\nshapiro.test(data_log$squid)\n\n\n    Shapiro-Wilk normality test\n\ndata:  data_log$squid\nW = 0.96226, p-value = 0.4613\n\nshapiro.test(data_log$limpet)\n\n\n    Shapiro-Wilk normality test\n\ndata:  data_log$limpet\nW = 0.96437, p-value = 0.5082\n\n\nAll 5 species fail to reject the null hypothesis that the data are normally distributed. Logging the data also helps deal with the outliers:\n\n# Generate boxplots\nboxplot(data_log[,-1])\n\n\n\n\nNote that we can only log the data if there are no zeroes:\n\n# Generate test data\ndata_test = data; data_test[1,6] = 0 # Change the first limpet value to 0\n\n# Try to log the data\ndata_test[1,] # Print first row\n\n  Hauls mackerel bluefin sardine squid limpet\n1     1    1.851    55.6   0.058     6      0\n\nlog(data_test[,-1])[1,] # Print logs of the first row\n\n  mackerel  bluefin   sardine    squid limpet\n1 0.615726 4.018183 -2.847312 1.791759   -Inf\n\n\nlog(0) returnes negative infinity. That’s going to be a problem later in our analysis. We can fix that by adding a small increment before taking the log. Keep in mind though that each species has a different magnitude in this dataset, and adding an inappropriate increment could cause us trouble later:\n\n# Test boxplots of different increments\nboxplot(log(data_test$limpet), # Warning because of -Inf\n        log(data_test$limpet + 1),\n        log(data_test$limpet + 0.001),\n        log(data_test$limpet + 0.000000001))\n\nWarning in bplt(at[i], wid = width[i], stats = z$stats[, i], out =\nz$out[z$group == : Outlier (-Inf) in boxplot 1 is not drawn\n\n\n\n\n\nIf the increment is too big, we eliminate the variance in our data. If the increment is to small, we create an outlier."
  },
  {
    "objectID": "a1a.html#running-pca",
    "href": "a1a.html#running-pca",
    "title": "1  Assignment 1a: Principal Components Analysis",
    "section": "1.3 Running PCA",
    "text": "1.3 Running PCA\nNow that we’ve checked and transformed our data, we’re ready to run PCA. There are two kinds of PCA: We can run PCA on the Covariance Matrix, or the Correlation Matrix.\n\n1.3.1 Covariance Matrix\nWe can run PCA on the covariance matrix as follows:\n\n# Run PCA - Covariance\npca_1 = princomp(data_log[,-1]) # We don't want haul in our PCA!\nsummary(pca_1)\n\nImportance of components:\n                          Comp.1    Comp.2    Comp.3     Comp.4      Comp.5\nStandard deviation     2.8055354 1.3857803 1.3351790 0.55247629 0.182937780\nProportion of Variance 0.6607195 0.1612035 0.1496458 0.02562199 0.002809263\nCumulative Proportion  0.6607195 0.8219229 0.9715687 0.99719074 1.000000000\n\n\nRunning a summary on our PCA gives us the standard deviation of each principal component, the proportion of variance explained by each principal component, and the cumulative variance explained as we add each component. Here, we see the first principal component explains 66% of the variance. The second explains 16%, which adds up to 82% with the first component, and so on up to component 5. We can visualize the cumulative variance explained with a scree plot:\n\n# Generate scree plot\nplot(pca_1, type = 'l') # Scree is built into the plot for PCA\n\n\n\n\nWe see most of the variance is explained by component 1, then a similar lesser amount is explained by 2 and 3, followed by another drop to 4 and 5.\n\n# Print loadings\nprint(loadings(pca_1),cutoff=0.00) #all loadings!\n\n\nLoadings:\n         Comp.1 Comp.2 Comp.3 Comp.4 Comp.5\nmackerel  0.018  0.294  0.047  0.527  0.796\nbluefin  -0.654  0.136  0.739 -0.089 -0.020\nsardine   0.060  0.626 -0.015  0.520 -0.577\nsquid    -0.745  0.049 -0.664  0.029  0.018\nlimpet    0.116  0.707 -0.102 -0.665  0.183\n\n               Comp.1 Comp.2 Comp.3 Comp.4 Comp.5\nSS loadings       1.0    1.0    1.0    1.0    1.0\nProportion Var    0.2    0.2    0.2    0.2    0.2\nCumulative Var    0.2    0.4    0.6    0.8    1.0\n\n\nThe PCA loadings are the correlations between the variables and each component. Here, we see bluefin and squid are strongly negatively correlated with component 1, while mackerel, sardine, and limpet are weakly positively correlated with component 1. We can continue this type of interpretation through the other components as well.\nOur PCA object also contains the PCA scores for each individual data point:\n\n# Print PCA scores\nhead(pca_1$scores)\n\n        Comp.1     Comp.2     Comp.3     Comp.4      Comp.5\n[1,] -3.551007 -2.2507718  0.6725187 -0.1223707 -0.06754585\n[2,]  2.484116 -0.6980669  0.4886052 -0.3932653 -0.53609582\n[3,]  2.425206 -1.4149241  0.9556963 -0.2274184 -0.07560834\n[4,] -3.339469 -1.4723306 -0.2089590 -0.8854067 -0.03598265\n[5,]  1.580988 -1.8002844 -4.6958830 -0.4313924  0.13590020\n[6,] -3.519487 -1.6187995  0.3362833  0.1040827  0.32134755\n\n\nScores are the value of each data point on each principal component. Lets try plotting them:\n\n# Plot scores - components 1 and 2\nplot(pca_1$scores[,1], # Scores on component 1\n     pca_1$scores[,2], # Scores on component 3\n     pch=16, # Point 16 (colored circle)\n     xlab=\"1st principal component\",ylab=\"2nd principal component\",main=\"Scores plot\") # Axis and plot labels\n\n\n\n\nThis generates a scatterplot showing us the value of each data point in principal components 1 (x) and 2 (y). Now lets add on the loadings:\n\n# Plot scores - components 1 and 2\nplot(pca_1$scores[,1], # Scores on component 1\n     pca_1$scores[,2], # Scores on component 3\n     pch=16, # Point 16 (colored circle)\n     xlab=\"1st principal component\",ylab=\"2nd principal component\",main=\"Scores plot\") # Axis and plot labels\n\n# Add loadings to plot\narrows(0,0, # Draw arrows from zero\n       pca_1$loadings[,1], # Draw to PC1 loading in X\n       pca_1$loadings[,2], # Draw to PC2 loading in Y\n       col=\"black\", length = 0.1) # Arrow color and arrowhead length\ntext(pca_1$loadings[,1],pca_1$loadings[,2],names(data_log[,-1]),cex=1.0 ,col=\"black\") # Add text labels for each variable\n\n\n\n\nThe arrows are a little small, so let’s add a scaling factor:\n\n# Plot scores - components 1 and 2\nplot(pca_1$scores[,1], # Scores on component 1\n     pca_1$scores[,2], # Scores on component 3\n     pch=16, # Point 16 (colored circle)\n     xlab=\"1st principal component\",ylab=\"2nd principal component\",main=\"Scores plot\") # Axis and plot labels\n\n# Add loadings to plot\nsf = 3 # Scaling factor\nsft = 3.2 # Scaling factor for text\narrows(0,0, # Draw arrows from zero\n       pca_1$loadings[,1]*sf, # Draw to PC1 * scaling factor loading in X\n       pca_1$loadings[,2]*sf, # Draw to PC2 * scaling factor loading in Y\n       col=\"black\", length = 0.1) # Arrow color and arrowhead length\ntext(pca_1$loadings[,1]*sft,pca_1$loadings[,2]*sft, names(data_log[,-1]), cex=1.0, col=\"black\") # Add text labels for each variable\n\n\n\n\nWhat about the haul number? Does that have an effect? Let’s try adding that on as well:\n\n# Create a color palette\ncolfunc = colorRampPalette(c('orangered1', 'turquoise2'))\n\n# Plot scores - components 1 and 2\nplot(pca_1$scores[,1], # Scores on component 1\n     pca_1$scores[,2], # Scores on component 3\n     pch=16, # Point 16 (colored circle)\n     col = colfunc(nrow(pca_1$scores)), # Color points by haul using our color palette\n     xlab=\"1st principal component\",ylab=\"2nd principal component\",main=\"Scores plot\") # Axis and plot labels\n\n# Add loadings to plot\nsf = 3 # Scaling factor\nsft = 3.2 # Scaling factor for text\narrows(0,0, # Draw arrows from zero\n       pca_1$loadings[,1]*sf, # Draw to PC1 * scaling factor loading in X\n       pca_1$loadings[,2]*sf, # Draw to PC2 * scaling factor loading in Y\n       col=\"black\", length = 0.1) # Arrow color and arrowhead length\ntext(pca_1$loadings[,1]*sft,pca_1$loadings[,2]*sft, names(data_log[,-1]), cex=1.0, col=\"black\") # Add text labels for each variable\n\n\n\n\nSince we used color for haul, we need to add a legend:\n\n# Set plot layout\nlayout(matrix(1:2,ncol=2), # 1 row, 2 columns\n       width = c(2,1), # Width\n       height = c(1,1)) # Height\n\n# Create a color palette\ncolfunc = colorRampPalette(c('orangered1', 'turquoise2'))\n\n# Plot scores - components 1 and 2\nplot(pca_1$scores[,1], # Scores on component 1\n     pca_1$scores[,2], # Scores on component 3\n     pch=16, # Point 16 (colored circle)\n     col = colfunc(nrow(pca_1$scores)), # Color points by haul using our color palette\n     xlab=\"1st principal component\",ylab=\"2nd principal component\",main=\"Scores plot\") # Axis and plot labels\n\n# Add loadings to plot\nsf = 3 # Scaling factor\nsft = 3.2 # Scaling factor for text\narrows(0,0, # Draw arrows from zero\n       pca_1$loadings[,1]*sf, # Draw to PC1 * scaling factor loading in X\n       pca_1$loadings[,2]*sf, # Draw to PC2 * scaling factor loading in Y\n       col=\"black\", length = 0.1) # Arrow color and arrowhead length\ntext(pca_1$loadings[,1]*sft,pca_1$loadings[,2]*sft, names(data_log[,-1]), cex=1.0, col=\"black\") # Add text labels for each variable\n\n# Generate legend\nlegend_image &lt;- as.raster(matrix(colfunc(nrow(pca_1$scores)), ncol=1))\nplot(c(0,2),c(0,1),type = 'n', axes = F,xlab = '', ylab = '', main = 'Haul')\ntext(x=1.5, y =seq(0,1,l=5), labels = seq(1,25,l=5))\nrasterImage(legend_image, 0, 0, 1,1)\n\n\n\n\nNow we have a completed scores plot with loadings arrows. How would you interpret this plot?\n\n\n1.3.2 Correlation Matrix\nNow let’s try the correlation matrix. The correlation matrix performs the same analysis, but on standardized data. The princomp() function does this for us if we set cor = T:\n\n# Run PCA - Correlation\npca_2 = princomp(data_log[,-1], cor = T)\nsummary(pca_2)\n\nImportance of components:\n                         Comp.1    Comp.2     Comp.3     Comp.4     Comp.5\nStandard deviation     1.595782 1.2503536 0.70708572 0.57220519 0.25041296\nProportion of Variance 0.509304 0.3126768 0.09999404 0.06548376 0.01254133\nCumulative Proportion  0.509304 0.8219809 0.92197491 0.98745867 1.00000000\n\n# In case you don't believe me, heres the covariance matrix if we pre-standardize the data\npca_test = princomp(scale(data_log[-1]))\nsummary(pca_test)\n\nImportance of components:\n                         Comp.1    Comp.2     Comp.3     Comp.4     Comp.5\nStandard deviation     1.563541 1.2250914 0.69279969 0.56064429 0.24535359\nProportion of Variance 0.509304 0.3126768 0.09999404 0.06548376 0.01254133\nCumulative Proportion  0.509304 0.8219809 0.92197491 0.98745867 1.00000000\n\n\nNow we can go through the same pattern of analyses as we did for covariance:\n\n# Generate scree plot\nplot(pca_2, type = 'l') # Scree is built into the plot for PCA\n\n\n\n# Print loadings\nprint(loadings(pca_2),cutoff=0.00) #all loadings!\n\n\nLoadings:\n         Comp.1 Comp.2 Comp.3 Comp.4 Comp.5\nmackerel  0.524  0.272  0.527  0.297  0.535\nbluefin  -0.198  0.682  0.264 -0.651 -0.050\nsardine   0.591  0.209  0.025  0.109 -0.771\nsquid    -0.233  0.645 -0.472  0.550  0.059\nlimpet    0.532  0.036 -0.655 -0.416  0.338\n\n               Comp.1 Comp.2 Comp.3 Comp.4 Comp.5\nSS loadings       1.0    1.0    1.0    1.0    1.0\nProportion Var    0.2    0.2    0.2    0.2    0.2\nCumulative Var    0.2    0.4    0.6    0.8    1.0\n\n# Set plot layout\nlayout(matrix(1:2,ncol=2), # 1 row, 2 columns\n       width = c(2,1), # Width\n       height = c(1,1)) # Height\n\n# Create a color palette\ncolfunc = colorRampPalette(c('orangered1', 'turquoise2'))\n\n# Plot scores - components 1 and 2\nplot(pca_2$scores[,1], # Scores on component 1\n     pca_2$scores[,2], # Scores on component 3\n     pch=16, # Point 16 (colored circle)\n     col = colfunc(nrow(pca_2$scores)), # Color points by haul using our color palette\n     xlab=\"1st principal component\",ylab=\"2nd principal component\",main=\"Scores plot\") # Axis and plot labels\n\n# Add loadings to plot\nsf = 3 # Scaling factor\nsft = 3.2 # Scaling factor for text\narrows(0,0, # Draw arrows from zero\n       pca_2$loadings[,1]*sf, # Draw to PC1 * scaling factor loading in X\n       pca_2$loadings[,2]*sf, # Draw to PC2 * scaling factor loading in Y\n       col=\"black\", length = 0.1) # Arrow color and arrowhead length\ntext(pca_2$loadings[,1]*sft,pca_2$loadings[,2]*sft, names(data_log[,-1]), cex=1.0, col=\"black\") # Add text labels for each variable\n\n# Generate legend\nlegend_image &lt;- as.raster(matrix(colfunc(nrow(pca_2$scores)), ncol=1))\nplot(c(0,2),c(0,1),type = 'n', axes = F,xlab = '', ylab = '', main = 'Haul')\ntext(x=1.5, y =seq(0,1,l=5), labels = seq(1,25,l=5))\nrasterImage(legend_image, 0, 0, 1,1)\n\n\n\n\nHow would you interpret this plot? Does it differ from the covariance plot?\n\n\n1.3.3 Alternative Methods\nThere are a few other ways you can generate, and/or plot your PCAs if you prefer.\nBiplot:\n\n# Exploring biplot\nbiplot(pca_1) # Covariance\n\n\n\nbiplot(pca_2) # Correlation\n\n\n\n\nggplot:\n\nlibrary(ggplot2)\n\n# ggplot version - Covariance\n\n# turn PCA scores into data frame\npca_1_plot = data.frame(Haul = data_log$Haul, pca_1$scores) \n\n# Turn PCA loadings into data frame (This gets a little complicated)\npca_1_loadings = as.data.frame(matrix(as.numeric(pca_1$loadings), \n                                      dim(pca_1$loadings)[1], dim(pca_1$loadings)[2]))\ncolnames(pca_1_loadings) = colnames(pca_1_plot)[-1]\n\n# Plot\nggplot(pca_1_plot, aes(x = Comp.1, y = Comp.2, color = Haul)) +\n  \n  # Scores\n  geom_point() + scale_colour_distiller(palette = 15) + \n  \n  # Loadings\n  geom_segment(data = pca_1_loadings, aes(x = 0, y = 0,xend = Comp.1 , yend = Comp.2), \n    arrow = arrow(length = unit(0.3, \"cm\"), type = \"open\", angle = 25), \n    linewidth = 1, color = \"darkblue\") + \n  \n  # Labels\n  geom_text(data = pca_1_loadings, color = 'darkblue', nudge_x = 0.2, nudge_y = 0.2, # Labels\n                aes(x = Comp.1, y = Comp.2, label = colnames(data_log)[-1]))\n\n\n\n# ggplot version - Correlation\n\n# turn PCA scores into data frame\npca_2_plot = data.frame(Haul = data_log$Haul, pca_2$scores) \n\n# Turn PCA loadings into data frame\npca_2_loadings = as.data.frame(matrix(as.numeric(pca_2$loadings), \n                                      dim(pca_2$loadings)[1], dim(pca_2$loadings)[2]))\ncolnames(pca_2_loadings) = colnames(pca_2_plot)[-1]\n\n# Plot\nggplot(pca_2_plot, aes(x = Comp.1, y = Comp.2, color = Haul)) +\n  \n  # Scores\n  geom_point() + scale_colour_distiller(palette = 15) + \n  \n  # Loadings\n  geom_segment(data = pca_2_loadings, aes(x = 0, y = 0,xend = Comp.1 , yend = Comp.2), \n               arrow = arrow(length = unit(0.3, \"cm\"), type = \"open\", angle = 25), \n               linewidth = 1, color = \"darkblue\") + \n  \n  # Labels\n  geom_text(data = pca_2_loadings, color = 'darkblue', nudge_x = 0.2, nudge_y = 0.2, # Labels\n            aes(x = Comp.1, y = Comp.2, label = colnames(data_log)[-1]))\n\n\n\n\nYou can also run PCA using the prcomp() function instead of princomp(), setting scale = T if you want the correlation matrix. You can then use autoplot() with the ggfortify package to plot the results.\n\n# ggplot v2\nlibrary(ggfortify)\n\n# Run PCA - Covariance\npca_1a = prcomp(data_log[,-1])\n\n# Run autoplot\nautoplot(pca_1a, data = data_log, color = 'Hauls', loadings = T, loadings.label = T)\n\n\n\n# Run PCA - Correlation\npca_2a = prcomp(data_log[,-1], scale = T)\n\n# Run autoplot\nautoplot(pca_2a, data = data_log, color = 'Hauls', loadings = T, loadings.label = T)"
  },
  {
    "objectID": "a1a.html#varimax-rotation-optional",
    "href": "a1a.html#varimax-rotation-optional",
    "title": "1  Assignment 1a: Principal Components Analysis",
    "section": "1.4 Varimax Rotation (Optional)",
    "text": "1.4 Varimax Rotation (Optional)\nVarimax rotation attempts to improve the interpretability of PCA results by lining up loadings with the axes. This can be useful, particularly with large numbers of variables.\n\n# Scaling factors\nsf = 2.5\nsft = 2.8\n\n# Varimax rotation - Covariance\nv1 = varimax(pca_1$loadings[,1:2])\nv1_scores = pca_1$scores[,1:2]%*%v1$rotmat\n\n# Plot scores - components 1 and 2\nplot(v1_scores[,1],v1_scores[,2],pch=15, col = colfunc(nrow(v1_scores)),\n     xlab=\"1st varimax component\",ylab=\"2nd varimax component\",main=\"varimax scores plot\")\n\n# Add loadings\narrows(0,0,v1$loadings[,1]*sf,v1$loadings[,2]*sf,col=\"black\")\ntext(v1$loadings[,1]*sft,v1$loadings[,2]*sft,names(data_log[,-1]),asp=1,cex=1.0 ,col=\"black\")\n\n\n\n# Varimax rotation - Correlation\nv2 = varimax(pca_2$loadings[,1:2])\nv2_scores = pca_2$scores[,1:2]%*%v2$rotmat\n\n# Plot scores - components 1 and 2\nplot(v2_scores[,1],v2_scores[,2],pch=15, col = colfunc(nrow(v2_scores)),\n     xlab=\"1st varimax component\",ylab=\"2nd varimax component\",main=\"varimax scores plot\")\n\n# Add loadings\narrows(0,0,v2$loadings[,1]*sf,v2$loadings[,2]*sf,col=\"black\")\ntext(v2$loadings[,1]*sft,v2$loadings[,2]*sft,names(data_log[,-1]),asp=1,cex=1.0 ,col=\"black\")\n\n\n\n\nNote that it’s pretty hard to tell the hauls apart using this color scale. Make sure your plots are always clear and readable."
  },
  {
    "objectID": "a1a.html#tips-for-your-assignment",
    "href": "a1a.html#tips-for-your-assignment",
    "title": "1  Assignment 1a: Principal Components Analysis",
    "section": "1.5 Tips for your assignment:",
    "text": "1.5 Tips for your assignment:\nSome things you may want to think about for your assignment:\n1. Do your covariance and correlation plots differ? Do you think one is better suited to answering your research question? Why? Is your answer conceptual, or does it have to do with the results? Both?\n2. How would you quantitatively examine the effect of haul on the PCA scores above? Is it associated with any of the principal components?\n3. How would you interpret your statistical results biologically? You don’t have to be right, but don’t be vague, and don’t contradict your results."
  },
  {
    "objectID": "a1b.html#looking-at-the-data",
    "href": "a1b.html#looking-at-the-data",
    "title": "2  Assignment 1b: Linear Discriminant Analysis",
    "section": "2.1 Looking at the data",
    "text": "2.1 Looking at the data\n\n# Load in data\nsnake = read.csv('snake.csv')\n\n# Look at data\nhead(snake)\n\n  Species   M1   M2   M3   M4   M5   M6\n1     A   41.6  6.7  8.2 12.2 24.7 27.0\n2     A   40.2  8.5  9.2 15.5 27.1 30.3\n3     A   40.4 12.6 14.2 19.6 46.9 26.8\n4     A   26.4  9.0  8.6 14.0 37.6 32.2\n5     A   34.4  7.0 12.1 11.1 31.0 35.8\n6     A   38.8  8.2 10.2 12.4 42.2 33.6\n\ndim(snake)\n\n[1] 35  7\n\n\nOur data is a 35 row, 7 column data frame. The first column identifies the species of snake (A or B). The other columns are morphological measurements of each individual snake. We want to know if we can use the morphological measurements of the snakes to determine their species. Let’s keep examining the data:\n\n# Make a boxplot\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n# Convert the data to long format so we can use ggplot\nsnake_long = pivot_longer(snake, # Enter data\n                          colnames(snake)[-1], # Pivot all columns except species\n                          names_to = 'Measurement', values_to = 'Value') # Feed labels to new data frame\n\n# Lets take a look at the new data frame\nhead(snake_long)\n\n# A tibble: 6 × 3\n  Species  Measurement Value\n  &lt;chr&gt;    &lt;chr&gt;       &lt;dbl&gt;\n1 \"   A  \" M1           41.6\n2 \"   A  \" M2            6.7\n3 \"   A  \" M3            8.2\n4 \"   A  \" M4           12.2\n5 \"   A  \" M5           24.7\n6 \"   A  \" M6           27  \n\n# We've converted from wide format to long format,\n# now all the data values are contained in a single column\n# which is described by a metadata column\n\n# You can also do this with melt from reshape2\nlibrary(reshape2)\n\n\nAttaching package: 'reshape2'\n\nThe following object is masked from 'package:tidyr':\n\n    smiths\n\nhead(melt(snake))\n\nUsing Species as id variables\n\n\n  Species variable value\n1     A         M1  41.6\n2     A         M1  40.2\n3     A         M1  40.4\n4     A         M1  26.4\n5     A         M1  34.4\n6     A         M1  38.8\n\n# Let's make a boxplot\nggplot(snake_long, aes(x = Measurement, y = Value, fill = Species)) +\n  geom_boxplot() + theme_classic()\n\n\n\n# We can do this in R base plot too\nboxplot(Value ~ Species*Measurement, # Plot value by species and measurement\n        data = snake_long, col = c('coral', 'turquoise2'), # Color by species\n        xaxt = 'n', xlab = 'Measurement') # Remove and label x axis\nlegend('topleft', legend = c('Species A', 'Species B'), fill = c('coral', 'turquoise2')) # Add a legend\naxis(1, at = seq(1.5,11.5,2), labels = colnames(snake)[-1]) # Add x axis back in with appropriate labels\n\n\n\n\nSome of our measurements are very similar across species, and others are quite different. Do they differ statistically as a whole?"
  },
  {
    "objectID": "a1b.html#manova",
    "href": "a1b.html#manova",
    "title": "2  Assignment 1b: Linear Discriminant Analysis",
    "section": "2.2 MANOVA",
    "text": "2.2 MANOVA\nThe purpose of LDA is to try to discriminate our snakes into species based on their measurements. However, that only makes sense to do if our two species of snake actually differ across the measurements. Our first step then is to discern whether our snake species differ as a multivariate whole. We’ll do this using a MANOVA.\n\n# Run MANOVA\nsm = manova(cbind(M1,M2,M3,M4,M5,M6) ~ Species, data = snake)\nsummary(sm, test = 'Hotelling')\n\n          Df Hotelling-Lawley approx F num Df den Df   Pr(&gt;F)    \nSpecies    1           1.2263   5.7229      6     28 0.000552 ***\nResiduals 33                                                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(sm, test = 'Wilks')\n\n          Df   Wilks approx F num Df den Df   Pr(&gt;F)    \nSpecies    1 0.44917   5.7229      6     28 0.000552 ***\nResiduals 33                                            \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nBy both the Hotelling’s and Wilks’ tests, our MANOVA is significant, indicating the snake species vary as a multivariate whole.\nWhat about our assumptions though? Our MANOVA assumptions are normality, linearity, and homogeneity of covariances. You’ve been told to assume the latter, so let’s skip that one.\n\n# Testing normality\nlibrary(mvnormtest)\nmshapiro.test(t(sm$residuals))\n\n\n    Shapiro-Wilk normality test\n\ndata:  Z\nW = 0.91571, p-value = 0.01075\n\n\nUh oh, the residuals are significantly non-normal. Let’s take a look at them visually:\n\n# Residual histogram\nhist(t(sm$residuals), breaks = 20)\n\n\n\n\nVisually, our residuals actually look quite close to normal. There may be some slight skew, or outliers that are forcing our residuals to statistical non-normality. We might be able to fix this by removing multivariate outliers, or by transforming some of our data (feel free to play around with these ideas!), but based on the shape of our residuals, it is unlikely that our model is fatally biased, and we may end up doing more harm than good. Based on this, we can conclude that our two species have significantly different morphometries given the measurements provided."
  },
  {
    "objectID": "a1b.html#linear-discriminant-analysis",
    "href": "a1b.html#linear-discriminant-analysis",
    "title": "2  Assignment 1b: Linear Discriminant Analysis",
    "section": "2.3 Linear Discriminant Analysis",
    "text": "2.3 Linear Discriminant Analysis\nNow that we’ve confirmed our species differ as a multivariate whole, we can try to use LDA to build a model to predict which species each snake belongs to based on its measurements.\n\n# LDA\nlibrary(MASS)\n\n\nAttaching package: 'MASS'\n\n\nThe following object is masked from 'package:dplyr':\n\n    select\n\nldaf1 &lt;- lda(Species ~ M1+M2+M3+M4+M5+M6, snake)\nldaf1\n\nCall:\nlda(Species ~ M1 + M2 + M3 + M4 + M5 + M6, data = snake)\n\nPrior probabilities of groups:\n      A         B   \n0.2857143 0.7142857 \n\nGroup means:\n           M1     M2    M3    M4     M5     M6\n   A   32.700  9.410 10.16 15.54 35.290 28.950\n   B   31.496 12.128 10.18 16.78 47.356 21.752\n\nCoefficients of linear discriminants:\n           LD1\nM1  0.01428023\nM2  0.29104494\nM3 -0.07327616\nM4 -0.05544769\nM5  0.03629586\nM6 -0.17208517\n\n\nRunning our LDA object tells us the prior probabilities used for each species (the proportion of each species in the data), the group means for each measure on each species, and the linear discriminant (LD1) for each measure. We can then plot the LD1 value for each individual:\n\n# Plot discriminant function analysis\n\n# Create a data frame to plot\nldaf_plot = cbind(snake, # Data\n                  predict(ldaf1)$x, # LD1 value for each individual given its measurements\n                  index = seq(1,nrow(snake), 1)) # Row/Individual number\n\n# Plot\nplot(LD1 ~ index, data = ldaf_plot, col = as.factor(snake$Species), pch = 16)\nlegend('topleft', legend = c('A', 'B'), col = c(1, 2), pch = 16) # Add legend\n\n\n\n\nHere we can see higher LD1 values are associated with species B, while lower LD1 values are associated with species A. This is just based on model fit however; how do we know we aren’t overfitting? One way to avoid overfitting is by jackknifing (AKA leave-one-out cross validation in this context). This method runs the model once without each point in the dataset, then calculates the posterior probability that the left out point belongs to each species. Let’s try it out:\n\n# LDA 2, CV = T\nldaf2 = lda(Species ~ M1+M2+M3+M4+M5+M6, snake, CV = T)\n\n# Gather posteriors\nas.data.frame(cbind(ldaf2$posterior, # Pull posteriors from ldaf2\n                    ResultantSpp=as.character(ldaf2$class))) # Pull predicted species (i.e. species with the higher posterior probability)\n\n                    A                    B   ResultantSpp\n1     0.897801237948675    0.102198762051325          A  \n2     0.957033498274347   0.0429665017256531          A  \n3   0.00486396795570833    0.995136032044292          B  \n4     0.939579607872302   0.0604203921276979          A  \n5     0.999020574119129 0.000979425880871094          A  \n6     0.958283942083953    0.041716057916047          A  \n7     0.859914694048175    0.140085305951825          A  \n8    0.0790276689479006      0.9209723310521          B  \n9     0.250711809994116    0.749288190005884          B  \n10    0.277233534989757    0.722766465010243          B  \n11   0.0654339037846645    0.934566096215335          B  \n12 8.13045175684633e-05    0.999918695482432          B  \n13  0.00857331675606214    0.991426683243938          B  \n14    0.119793120831736    0.880206879168264          B  \n15    0.868897347918874    0.131102652081126          A  \n16    0.291404395123413    0.708595604876587          B  \n17    0.580893601645515    0.419106398354485          A  \n18    0.407526292222816    0.592473707777184          B  \n19    0.097139347240766    0.902860652759234          B  \n20   0.0629455676122022    0.937054432387798          B  \n21   0.0262176442553781    0.973782355744622          B  \n22   0.0110464412594654    0.988953558740534          B  \n23     0.37967670676917     0.62032329323083          B  \n24  0.00300786068222619    0.996992139317774          B  \n25   0.0331152011340242    0.966884798865976          B  \n26  0.00270158005931187    0.997298419940688          B  \n27   0.0161164609849135    0.983883539015087          B  \n28  0.00346528534198866    0.996534714658011          B  \n29    0.761253716426843    0.238746283573157          A  \n30   0.0597294571669348    0.940270542833065          B  \n31  0.00139900114299064    0.998600998857009          B  \n32   0.0146304515487079    0.985369548451292          B  \n33   0.0215114427320867    0.978488557267913          B  \n34  0.00359029891803412    0.996409701081966          B  \n35 8.92739861715428e-05    0.999910726013828          B  \n\n\nHow does this differ from the predictions from our first model?\n\n# Pull ldaf1 model predictions\nldaf_pred = predict(ldaf1)$class\n\n# Gather Predictions\nldaf_diff = data.frame(ldaf1 = as.character(ldaf_pred), ldaf2 = as.character(ldaf2$class))\n\n# Add match column\nldaf_diff$match = (ldaf_diff$ldaf1 == ldaf_diff$ldaf2)\n\n# Which ones are different?\nldaf_diff[which(ldaf_diff$match == F),]\n\n    ldaf1  ldaf2 match\n17    B      A   FALSE\n29    B      A   FALSE\n\n\nIndividuals 17 and 29 both differed in species prediction between the model fit and the jackknife posterior probability. Now let’s check the accuracy of our model fit:\n\n# Calculate error\nldaf_wrong = length(which(ldaf_pred != snake$Species)) # Number of incorrect predictions\nldaf_err = ldaf_wrong/nrow(snake) # Divide by number of individuals for error\n\n# Print error\nldaf_wrong\n\n[1] 5\n\nldaf_err\n\n[1] 0.1428571\n\n\nOur model classified 5 out of 35 (~14.3%) of the snakes as the incorrect species, meaning 30/35 were correct (~85.7%). Not bad, but can we do better?"
  },
  {
    "objectID": "a1b.html#model-selection",
    "href": "a1b.html#model-selection",
    "title": "2  Assignment 1b: Linear Discriminant Analysis",
    "section": "2.4 Model Selection",
    "text": "2.4 Model Selection\nOur previous model used all 6 measurements, but do we really need all of them, or are some of them unhelpful (or even detrimental)? To test this, we can run model selection using the stepclass() function:\n\n# stepclass package\nlibrary(klaR)\n\n# Model selection (forward)\nms_f = stepclass(Species ~ M1+M2+M3+M4+M5+M6,data=snake,\n          method=\"lda\", fold=35, direction=\"forward\")\n\n `stepwise classification', using 35-fold cross-validated correctness rate of method lda'.\n\n\n35 observations of 6 variables in 2 classes; direction: forward\n\n\nstop criterion: improvement less than 5%.\n\n\ncorrectness rate: 0.85714;  in: \"M6\";  variables (1): M6 \n\n hr.elapsed min.elapsed sec.elapsed \n       0.00        0.00        0.69 \n\n# Print model selection result\nms_f\n\nmethod      : lda \nfinal model : Species ~ M6\n&lt;environment: 0x00000169675df600&gt;\n\ncorrectness rate = 0.8571 \n\n\nAfter model selection, we end up with a model using only M6 to predict species, with a correctness rate of 85.7%. This model has the same correctness as the full model, using only one measurement. In other words, this model is more efficient - it gets to the same accuracy using less information.\nThis model was generated using forward model selection, meaning the selection process works exclusively by adding variables to the model. We can also do the opposite:\n\n# stepclass package\nlibrary(klaR)\n\n# Model selection (forward)\nms_b = stepclass(Species ~ M1+M2+M3+M4+M5+M6,data=snake,\n          method=\"lda\", fold=35, direction=\"backward\")\n\n `stepwise classification', using 35-fold cross-validated correctness rate of method lda'.\n\n\n35 observations of 6 variables in 2 classes; direction: backward\n\n\nstop criterion: improvement less than 5%.\n\n\ncorrectness rate: 0.8;  starting variables (6): M1, M2, M3, M4, M5, M6 \ncorrectness rate: 0.85714;  out: \"M5\";  variables (5): M1, M2, M3, M4, M6 \n\n hr.elapsed min.elapsed sec.elapsed \n       0.00        0.00        1.04 \n\n# Print model selection result\nms_b\n\nmethod      : lda \nfinal model : Species ~ M1 + M2 + M3 + M4 + M6\n&lt;environment: 0x0000016967b5c5a0&gt;\n\ncorrectness rate = 0.8571 \n\n\nBackwards model selection works by removing variables from the full model. This means backwards selection should always return a model with a equal or more variables than forwards selection.\nLastly, we can run both:\n\n# stepclass package\nlibrary(klaR)\n\n# Model selection (forward)\nms_d = stepclass(Species ~ M1+M2+M3+M4+M5+M6,data=snake,\n          method=\"lda\", fold=35, direction=\"both\")\n\n `stepwise classification', using 35-fold cross-validated correctness rate of method lda'.\n\n\n35 observations of 6 variables in 2 classes; direction: both\n\n\nstop criterion: improvement less than 5%.\n\n\ncorrectness rate: 0.85714;  in: \"M6\";  variables (1): M6 \n\n hr.elapsed min.elapsed sec.elapsed \n       0.00        0.00        0.72 \n\n# Print model selection result\nms_d\n\nmethod      : lda \nfinal model : Species ~ M6\n&lt;environment: 0x00000169683cfa48&gt;\n\ncorrectness rate = 0.8571"
  },
  {
    "objectID": "a1b.html#plotting-probabilities",
    "href": "a1b.html#plotting-probabilities",
    "title": "2  Assignment 1b: Linear Discriminant Analysis",
    "section": "2.5 Plotting Probabilities",
    "text": "2.5 Plotting Probabilities\nLets finish off by making some plots to visualize our LDA model results.\n\n# Pick a model to plot\nldaf3 = lda(Species ~ M6, data = snake)\n\n# Plot density curve\nplot(ldaf3, dimen = 1, type = 'dens')\n\n\n\n\nThis plots the posterior probabilites of an individual belonging to either species given its LD1 value. Remember from earlier that species A is associated with lower LD1 values.\nWe can also make this plot as a histogram:\n\n# Plot density curve\npar(mar = c (4,4,4,4))\nplot(ldaf3, dimen = 1, type = 'hist')\n\n\n\n\nOr combine both plots:\n\n# Plot density curve\npar(mar = c (4,4,4,4))\nplot(ldaf3, dimen = 1, type = 'both')\n\n\n\n\nAs always, we can also do this with ggplot too:\n\n# Predict species\nldaf3_pred = predict(ldaf3)\n\n# Plot\npred_species = as.data.frame(ldaf3_pred$x) # Gather LD1 values\npred_species$Species = snake$Species # Gather true species from data\n\n# Plot\nggplot(pred_species, aes(x = LD1, fill = Species))+\n  geom_density(alpha = 0.4)# alpha tells you how transparent the plots will be"
  },
  {
    "objectID": "a1b.html#tips-for-your-assignment",
    "href": "a1b.html#tips-for-your-assignment",
    "title": "2  Assignment 1b: Linear Discriminant Analysis",
    "section": "2.6 Tips for your assignment",
    "text": "2.6 Tips for your assignment\nSome things you may want to think about for your assignment:\n1. How would you pick which model you think is best? What factors would you consider? Are there any factors you would consider other than those discussed in this tutorial?\n2. LDA also assumes the data are independent. Do we know this assumption is respected? Why or why not? What would constitute it not being respected?\n3. How would you interpret your statistical results biologically (can be in terms of the snakes, how you would study them, or both)? You don’t have to be right, but don’t be vague, and don’t contradict your results."
  },
  {
    "objectID": "a1c.html#looking-at-the-data",
    "href": "a1c.html#looking-at-the-data",
    "title": "3  Assignment 1c: Cluster Analysis and Multidimensional Scaling",
    "section": "3.1 Looking at the data",
    "text": "3.1 Looking at the data\nYou know the drill by now:\n\n# Load in data\ndata = read.csv('monkey.csv', row.names = 1) # First column is row names\ndata # Print data\n\n      ind1 ind2 ind3 ind4 ind5 ind6 ind7 ind8 ind9 ind10 ind11 ind12 ind13\nind1    21    2    2   10    2    2    8    0    0     8    14    12     4\nind2     2   21   16    2   16    8    2    2    4     4     4     0     2\nind3     2   16   21    0   10   16    2    0    2     4     4     0     2\nind4    10    2    0   21    2    2   16    2    2     8    12     8     4\nind5     2   16   10    2   21   10    2    4    0     2     4     4     2\nind6     2    8   16    2   10   21    4    2    0     0     0     4     4\nind7     8    2    2   16    2    4   21    4    2    16     8     8     4\nind8     0    2    0    2    4    2    4   21    0     2     0     0     0\nind9     0    4    2    2    0    0    2    0   21     0     4     0     0\nind10    8    4    4    8    2    0   16    2    0    21    14    14     2\nind11   14    4    4   12    4    0    8    0    4    14    21    12     4\nind12   12    0    0    8    4    4    8    0    0    14    12    21     2\nind13    4    2    2    4    2    4    4    0    0     2     4     2    21\n\n\nOur data is a matrix containing the number of social interactions observed between individuals in a group of monkeys at the zoo. The matrix is symmetrical - the top/right half is identical to the bottom/left half."
  },
  {
    "objectID": "a1c.html#calculating-dissimilarity",
    "href": "a1c.html#calculating-dissimilarity",
    "title": "3  Assignment 1c: Cluster Analysis and Multidimensional Scaling",
    "section": "3.2 Calculating Dissimilarity",
    "text": "3.2 Calculating Dissimilarity\nFor this assignment we’ll be using 3 R functions: hclust, metaMDS (from the vegan package), isoMDS (from the MASSpackage), and cmdscale(). Let’s see what type of input data those functions need:\n\n# Check help functions\nlibrary(vegan)\nlibrary(MASS)\n?hclust()\n?metaMDS()\n?isoMDS()\n?cmdscale()\n\nYou’ll notice all of these functions require a dissimilarity matrix produced by dist. Let’s start by running dist().\n\n# Convert data to a dist object\ndist = as.dist(data)\ndist # Print dist\n\n      ind1 ind2 ind3 ind4 ind5 ind6 ind7 ind8 ind9 ind10 ind11 ind12\nind2     2                                                          \nind3     2   16                                                     \nind4    10    2    0                                                \nind5     2   16   10    2                                           \nind6     2    8   16    2   10                                      \nind7     8    2    2   16    2    4                                 \nind8     0    2    0    2    4    2    4                            \nind9     0    4    2    2    0    0    2    0                       \nind10    8    4    4    8    2    0   16    2    0                  \nind11   14    4    4   12    4    0    8    0    4    14            \nind12   12    0    0    8    4    4    8    0    0    14    12      \nind13    4    2    2    4    2    4    4    0    0     2     4     2\n\n\nNow our data is in a dist object. All of the redundant entries in the data have been removed.\nRight now, our data reflects similarity (i.e. high numbers reflect greater association between individuals). We need to convert it to dissimilarity. Dissimilarity is simply the opposite of similarity. We can convert similarity to dissimilarity by subtracting each data value from the maximum of the data.\n\n# Convert to dissimilarity\ndist = max(dist) - dist\ndist # Print dist\n\n      ind1 ind2 ind3 ind4 ind5 ind6 ind7 ind8 ind9 ind10 ind11 ind12\nind2    14                                                          \nind3    14    0                                                     \nind4     6   14   16                                                \nind5    14    0    6   14                                           \nind6    14    8    0   14    6                                      \nind7     8   14   14    0   14   12                                 \nind8    16   14   16   14   12   14   12                            \nind9    16   12   14   14   16   16   14   16                       \nind10    8   12   12    8   14   16    0   14   16                  \nind11    2   12   12    4   12   16    8   16   12     2            \nind12    4   16   16    8   12   12    8   16   16     2     4      \nind13   12   14   14   12   14   12   12   16   16    14    12    14\n\n\nNow we’re ready to run our analyses!"
  },
  {
    "objectID": "a1c.html#hierarchical-cluster-analysis",
    "href": "a1c.html#hierarchical-cluster-analysis",
    "title": "3  Assignment 1c: Cluster Analysis and Multidimensional Scaling",
    "section": "3.3 Hierarchical Cluster Analysis",
    "text": "3.3 Hierarchical Cluster Analysis\nRemember from lecture there are 4 types of hierarchical cluster analysis:\n\nSingle linkage\nAverage linkage\nComplete linkage\nWard linkage\n\nLet’s run through them one by one:\n\n3.3.1 Single linkage\nWe can run all 4 types of cluster analysis using the hclust() R function:\n\n# run single linkage cluster analysis\nclust_1 = hclust(dist, method = 'single')\nclust_1 # print object\n\n\nCall:\nhclust(d = dist, method = \"single\")\n\nCluster method   : single \nNumber of objects: 13 \n\n\nPrinting the hclust object doesn’t really tell us much. For more detail, we’re going to have to plot it:\n\n# Plot single linkage tree\nplot(clust_1, hang = -1, main = 'Single linkage', \n     ylab = 'Dissimilarity', # Label y axis\n     xlab = '', sub = '') # Remove x-axis label\n\n\n\n\nThis outputs a tree showing the associations between our individual monkeys. dissimilarity is on the y-axis. The greater the distance between individuals on the y-axis, the greater their dissimilarity. Our tree has grouped the monkeys according to how frequently they interact with each other. For example. individuals 2, 3, 5, and 6 interact often, as evidenced by their low dissimilarity.\nBut how well does this tree fit the data? To answer that question, we need to calculate the cophenetic correlation coefficient (CCC):\n\n# Calculate CCC\ncoph_1 = cophenetic(clust_1) # Get cophenetic\nccc_1 = cor(coph_1, dist) # Calculate correlation of the cophenetic with the data\nccc_1 # Print CCC\n\n[1] 0.9036043\n\n\nThat’s a pretty high correlation coefficient, indicating our dendrogram represented the structure in the original data very well. Let’s try some other methods:\n\n\n3.3.2 Average Linkage\n\n# run cluster analysis\nclust_2 = hclust(dist, method = 'average')\n\n# Plot\nplot(clust_2, hang = -1, main = 'Average linkage', ylab = 'Dissimilarity', xlab = '', sub = '')\n\n\n\n# Calculate CCC\ncoph_2 = cophenetic(clust_2)\nccc_2 = cor(coph_2, dist)\nccc_2\n\n[1] 0.9288949\n\n\n\n\n3.3.3 Complete Linkage\n\n# run cluster analysis\nclust_3 = hclust(dist, method = 'complete')\n\n# Plot\nplot(clust_3, hang = -1, main = 'Complete linkage', ylab = 'Dissimilarity', xlab = '', sub = '')\n\n\n\n# Calculate CCC\ncoph_3 = cophenetic(clust_3)\nccc_3 = cor(coph_3, dist)\nccc_3\n\n[1] 0.9141956\n\n\n\n\n3.3.4 Ward Linkage\n\n# run cluster analysis\nclust_4 = hclust(dist, method = 'ward.D')\n\n# Plot\nplot(clust_4, hang = -1, main = 'Ward linkage', ylab = 'Dissimilarity', xlab = '', sub = '')\n\n\n\n# Calculate CCC\ncoph_4 = cophenetic(clust_4)\nccc_4 = cor(coph_4, dist)\nccc_4\n\n[1] 0.7633159\n\n\nEach method gives a slightly different tree and CCC value. Where are they similar? Where do they differ? Which one(s) would you trust? Why?"
  },
  {
    "objectID": "a1c.html#multidimensional-scaling",
    "href": "a1c.html#multidimensional-scaling",
    "title": "3  Assignment 1c: Cluster Analysis and Multidimensional Scaling",
    "section": "3.4 Multidimensional Scaling",
    "text": "3.4 Multidimensional Scaling\nAnother method we can use to test for associations between our monkeys is multidimensional scaling (MDS). There are two types of MDS: non-metric, and metric MDS. Let’s start with non-metric MDS.\n\n3.4.1 Non-Metric MDS\n\n# Run non-metric MDS - metaMDS\nmds1 = metaMDS(dist, wascores = F)\n\nRun 0 stress 0.07592385 \nRun 1 stress 0.07366297 \n... New best solution\n... Procrustes: rmse 0.1937863  max resid 0.5647321 \nRun 2 stress 0.07575137 \nRun 3 stress 0.07239302 \n... New best solution\n... Procrustes: rmse 0.1707883  max resid 0.5155234 \nRun 4 stress 0.07572991 \nRun 5 stress 0.07227846 \n... New best solution\n... Procrustes: rmse 0.01244117  max resid 0.03072205 \nRun 6 stress 0.120356 \nRun 7 stress 0.07239301 \n... Procrustes: rmse 0.01244622  max resid 0.03088513 \nRun 8 stress 0.08055013 \nRun 9 stress 0.07239299 \n... Procrustes: rmse 0.01247495  max resid 0.03097102 \nRun 10 stress 0.08055013 \nRun 11 stress 0.07358653 \nRun 12 stress 0.07366297 \nRun 13 stress 0.0757299 \nRun 14 stress 0.08571807 \nRun 15 stress 0.072393 \n... Procrustes: rmse 0.0124875  max resid 0.03101887 \nRun 16 stress 0.08575957 \nRun 17 stress 0.07358653 \nRun 18 stress 0.07358653 \nRun 19 stress 0.07366297 \nRun 20 stress 0.07366297 \n*** Best solution was not repeated -- monoMDS stopping criteria:\n    16: stress ratio &gt; sratmax\n     4: scale factor of the gradient &lt; sfgrmin\n\n# Print mds results\nmds1\n\n\nCall:\nmetaMDS(comm = dist, wascores = F) \n\nglobal Multidimensional Scaling using monoMDS\n\nData:     dist \nDistance: user supplied \n\nDimensions: 2 \nStress:     0.07227846 \nStress type 1, weak ties\nBest solution was not repeated after 20 tries\nThe best solution was from try 5 (random start)\nScaling: centring, PC rotation \nSpecies: scores missing\n\n\nBy default, metaMDS has two dimensions. This MDS has a stress value of 0.072. Remember from lecture that stress &lt; 0.10 is a “good representation”, so this MDS result is pretty good. If we want, we can test different numbers of dimensions (k) and create a scree plot to find the best one:\n\n# Create a container object\nscree = data.frame(k = 1:5, stress = NA)\n\n# Loop through k 1 to 5\nfor(k in 1:5){\n  \n  # Run MDS\n  mds = metaMDS(dist, wascores = F, k = k) # Set k to our loop index\n  \n  # Pull out stress\n  scree[k,'stress'] = mds$stress # Fill kth row of the column 'stress' in scree\n  \n} # End loop\n\n\n# Print results\nscree\n\n  k       stress\n1 1 2.209873e-01\n2 2 7.227846e-02\n3 3 8.412708e-05\n4 4 3.140980e-04\n5 5 9.087882e-05\n\n# Make scree plot\nplot(stress ~ k, data = scree, # Plot stress against k\n     type = 'b', # Lines and points\n     pch = 16) # Point 16 (filled circle)\nabline(h = 0.1, lty = 'dashed') # Plot a dashed line at 0.1\n\n\n\n\nWe have an elbow at k=3, but we also get warnings that our dataset may be too small using k=3. The stress at k=2 is low enough that we can stick to using that.\nLet’s plot our results:\n\n# Plot result\nplot(mds1, type = 't')\n\nspecies scores not available\n\n\n\n\n\nHere we’ve plotted the values of our two MDS dimensions against each other for each individual. Similar to the cluster analysis, we see certain individuals are grouped together. Is it the same groups of individuals? What does that tell you about your results?\nLet’s try a different non-metric MDS function:\n\n# Run non-metric MDS - isoMDS\nmds2 = isoMDS(dist)\n\nError in isoMDS(dist): zero or negative distance between objects 2 and 3\n\n\nUh oh. This function doesn’t like zeroes in the data. Let’s fix that by translating our data to proportions, and adding a small increment.\n\n# Translate to proportions\ndist2 = dist/max(dist)\n\n# Add an increment\ndist2 = dist2 + 0.0001\n\n# Print new dist\ndist2\n\n        ind1   ind2   ind3   ind4   ind5   ind6   ind7   ind8   ind9  ind10\nind2  0.8751                                                               \nind3  0.8751 0.0001                                                        \nind4  0.3751 0.8751 1.0001                                                 \nind5  0.8751 0.0001 0.3751 0.8751                                          \nind6  0.8751 0.5001 0.0001 0.8751 0.3751                                   \nind7  0.5001 0.8751 0.8751 0.0001 0.8751 0.7501                            \nind8  1.0001 0.8751 1.0001 0.8751 0.7501 0.8751 0.7501                     \nind9  1.0001 0.7501 0.8751 0.8751 1.0001 1.0001 0.8751 1.0001              \nind10 0.5001 0.7501 0.7501 0.5001 0.8751 1.0001 0.0001 0.8751 1.0001       \nind11 0.1251 0.7501 0.7501 0.2501 0.7501 1.0001 0.5001 1.0001 0.7501 0.1251\nind12 0.2501 1.0001 1.0001 0.5001 0.7501 0.7501 0.5001 1.0001 1.0001 0.1251\nind13 0.7501 0.8751 0.8751 0.7501 0.8751 0.7501 0.7501 1.0001 1.0001 0.8751\n       ind11  ind12\nind2               \nind3               \nind4               \nind5               \nind6               \nind7               \nind8               \nind9               \nind10              \nind11              \nind12 0.2501       \nind13 0.7501 0.8751\n\n\nLet’s make sure this doesn’t mess with our results:\n\n# Run non-metric MDS - metaMDS\nmds1 = metaMDS(dist2, wascores = F)\n\nRun 0 stress 0.07575137 \nRun 1 stress 0.1840572 \nRun 2 stress 0.08055013 \nRun 3 stress 0.205126 \nRun 4 stress 0.120356 \nRun 5 stress 0.08055013 \nRun 6 stress 0.08566789 \nRun 7 stress 0.07875788 \nRun 8 stress 0.07882366 \nRun 9 stress 0.072393 \n... New best solution\n... Procrustes: rmse 0.2253582  max resid 0.6639831 \nRun 10 stress 0.1396043 \nRun 11 stress 0.07589516 \nRun 12 stress 0.07358653 \nRun 13 stress 0.072393 \n... New best solution\n... Procrustes: rmse 9.314091e-05  max resid 0.0001993305 \n... Similar to previous best\nRun 14 stress 0.07875788 \nRun 15 stress 0.07875788 \nRun 16 stress 0.072393 \n... Procrustes: rmse 1.561236e-05  max resid 3.488764e-05 \n... Similar to previous best\nRun 17 stress 0.07227846 \n... New best solution\n... Procrustes: rmse 0.01245818  max resid 0.03077209 \nRun 18 stress 0.08566789 \nRun 19 stress 0.07572991 \nRun 20 stress 0.07239303 \n... Procrustes: rmse 0.012435  max resid 0.03085577 \n*** Best solution was not repeated -- monoMDS stopping criteria:\n    16: stress ratio &gt; sratmax\n     4: scale factor of the gradient &lt; sfgrmin\n\n# Print mds results\nmds1\n\n\nCall:\nmetaMDS(comm = dist2, wascores = F) \n\nglobal Multidimensional Scaling using monoMDS\n\nData:     dist2 \nDistance: user supplied \n\nDimensions: 2 \nStress:     0.07227846 \nStress type 1, weak ties\nBest solution was not repeated after 20 tries\nThe best solution was from try 17 (random start)\nScaling: centring, PC rotation \nSpecies: scores missing\n\n# Plot result\nplot(mds1, type = 't')\n\nspecies scores not available\n\n\n\n\n\nThe values have shifted around a bit but the structure and interpretation of the plot is the same. Let’s continue on:\n\n# Run non-metric MDS - isoMDS\nmds2 = isoMDS(dist2)\n\ninitial  value 24.760322 \niter   5 value 14.153502\niter  10 value 12.254154\niter  15 value 11.639473\niter  20 value 11.360460\nfinal  value 11.341572 \nconverged\n\n# Print output\nmds2\n\n$points\n            [,1]         [,2]\nind1   0.5060798  0.103253718\nind2  -0.6157097 -0.285522725\nind3  -0.6133549 -0.310223762\nind4   0.5008471  0.144443835\nind5  -0.6264450 -0.279477605\nind6  -0.6228134 -0.325577873\nind7   0.4940123  0.147103149\nind8  -0.6783876  0.680257989\nind9  -0.2575043  1.075686777\nind10  0.5482152  0.033286470\nind11  0.5478840  0.082682890\nind12  0.5895070  0.001005794\nind13  0.2276697 -1.066918657\n\n$stress\n[1] 11.34157\n\n\nThe modelling algorithms seems to be a little different, and we end up with a different stress result - in this case, one that is above the 10% threshold (note that stress is in % in this function, unlike metaMDS where it is in proportion). Let’s try another scree plot:\n\n# Create a container object\nscree = data.frame(k = 1:5, stress = NA)\n\n# Loop through k 1 to 5\nfor(k in 1:5){\n  \n  # Run MDS\n  mds = isoMDS(dist2, k = k) # Set k to our loop index\n  \n  # Pull out stress\n  scree[k,'stress'] = mds$stress # Fill kth row of the column 'stress' in scree\n  \n} # End loop\n\n\n# Print results\nscree\n\n  k      stress\n1 1 36.54857293\n2 2 11.34157190\n3 3  0.04614441\n4 4  0.12630298\n5 5  0.19439990\n\n# Make scree plot\nplot(stress ~ k, data = scree, # Plot stress against k\n     type = 'b', # Lines and points\n     pch = 16) # Point 16 (filled circle)\nabline(h = 10, lty = 'dashed') # Plot a dashed line at 0.1\n\n\n\n\nIn this case, it seems we’re better off using 3 dimensions:\n\n# Run non-metric MDS - isoMDS\nmds2 = isoMDS(dist2, k = 3)\n\ninitial  value 18.960422 \niter   5 value 11.725940\niter  10 value 6.417141\niter  15 value 4.149185\niter  20 value 1.466748\niter  25 value 0.764657\niter  30 value 0.449114\niter  35 value 0.302911\niter  40 value 0.156116\niter  45 value 0.087536\niter  50 value 0.046144\nfinal  value 0.046144 \nstopped after 50 iterations\n\n# Print output\nmds2\n\n$points\n            [,1]       [,2]       [,3]\nind1   2.0028765  0.4079841 -0.4202376\nind2  -2.0901193 -1.3657278  1.2720375\nind3  -2.0910832 -1.3666943  1.2729356\nind4   2.0066696  0.4042391 -0.4161698\nind5  -2.0896284 -1.3631915  1.2769256\nind6  -2.0921681 -1.3637290  1.2724192\nind7   2.0032691  0.4111298 -0.4185160\nind8  -2.1600174  2.2033842 -1.8938700\nind9  -0.6641520  2.9972846  2.5707229\nind10  2.0009095  0.4046552 -0.4185896\nind11  2.0041166  0.4044773 -0.4197885\nind12  2.0019583  0.4023552 -0.4223419\nind13 -0.8326313 -2.1761669 -3.2555274\n\n$stress\n[1] 0.04614441\n\n\nLet’s plot our results:\n\n# Plot isoMDS\nplot(mds2$points[,1], mds2$points[,2], # MDS dimension 1 and 2 values\n     type = 'n', # Don't plot any points\n     xlab = 'Dim 1', ylab = 'Dim 2', main = 'Metric MDS') # Labelling\n\n# Plot individual names\ntext(mds2$points[,1], mds2$points[,2], rownames(data))\n\n\n\n\nAll of our grouped individuals are plotted on top of each other. Let’s try adding some random jiggle so we can see them\n\n# Plot isoMDS\nplot(mds2$points[,1], mds2$points[,2], # MDS dimension 1 and 2 values\n     type = 'n', # Don't plot any points\n     xlab = 'Dim 1', ylab = 'Dim 2', main = 'Metric MDS', # Labelling\n     xlim = c(-2.5, 2.5), ylim = c(3, -3)) # Set axis limits\n\n# Set random seed for consistency\nset.seed(1212)\n\n# Plot individual names\ntext(mds2$points[,1] + rnorm(13, 0, 0.2), # Add random values pulled from a \n     mds2$points[,2] + rnorm(13, 0, 0.2), # normal distribution with mean 0, sd 0.2\n     rownames(data)) # Add names\n\n\n\n\nThat’s a bit better. We can also add some color to this plot if we want - say, individuals 6 to 9 are juveniles:\n\n# Plot isoMDS\nplot(mds2$points[,1], mds2$points[,2], # MDS dimension 1 and 2 values\n     type = 'n', # Don't plot any points\n     xlab = 'Dim 1', ylab = 'Dim 2', main = 'Metric MDS', # Labelling\n     xlim = c(-2.5, 2.5), ylim = c(3, -3)) # Set axis limits\n\n# Set random seed for consistency\nset.seed(1212)\n\n# Juvenile identifier\nad = c(rep(1,5), rep(0,4), rep(1,4)) # ad is 1 for first 5 and last 4\nad\n\n [1] 1 1 1 1 1 0 0 0 0 1 1 1 1\n\n# Plot individual names\ntext(mds2$points[,1] + rnorm(13, 0, 0.2), # Add random values pulled from a \n     mds2$points[,2] + rnorm(13, 0, 0.2), # normal distribution with mean 0, sd 0.2\n     rownames(data), # Add names\n     col = ifelse(ad == 0, 'purple', 'orange')) # color \n# Add a legend\nlegend('topright', legend = c('Juvenile', 'Adult'), fill = c('purple', 'orange'))\n\n\n\n\nDoes this plot match the previous one, and/or the cluster analyses?\n\n\n3.4.2 Metric MDS\nWe can run metric MDS using the cmdscale() function:\n\n# run metric MDS\nmds3 = cmdscale(dist, eig = T)\nmds3\n\n$points\n             [,1]       [,2]\nind1   5.84977914  2.7981654\nind2  -7.46899061 -0.4452479\nind3  -7.87360160  2.4742095\nind4   6.04970828 -1.1964346\nind5  -6.77887791  2.8518073\nind6  -7.21161499  3.9150940\nind7   4.79289905 -0.9896933\nind8  -2.46317365 -5.3304368\nind9  -1.86216019 -9.7770302\nind10  5.45394235  1.1317599\nind11  5.27120921 -0.1097836\nind12  6.20052885  3.6063451\nind13  0.04035206  1.0712450\n\n$eig\n [1]  4.150450e+02  1.794715e+02  1.684147e+02  1.309366e+02  6.931537e+01\n [6]  5.811388e+01  3.306204e+01  1.780496e+01 -4.263256e-14 -8.643935e+00\n[11] -2.208342e+01 -4.468321e+01 -7.952271e+01\n\n$x\nNULL\n\n$ac\n[1] 0\n\n$GOF\n[1] 0.4844901 0.5545014\n\n\nMetric MDS doesn’t have stress. Instead, we have to look at goodness of fit (GOF) to assess how well the analysis worked. GOF is similar to an R2 value, where numbers closer to 1 indicate a better fit (though be wary of overfitting!). There are two different GOF values for each metric MDS.\nAs with the other MDS functions, k defaults to 2. We can make another scree plot:\n\n# Create a container object\nscree = data.frame(k = 1:5, GOF1 = NA, GOF2 = NA)\n\n# Loop through k 1 to 5\nfor(k in 1:5){\n  \n  # Run MDS\n  mds = cmdscale(dist, eig = T, k = k) # Set k to our loop index\n  \n  # Pull out stress\n  scree[k,c(2,3)] = mds$GOF # Fill kth row of the GOF columns in scree\n  \n} # End loop\n\n\n# Print results\nscree\n\n  k      GOF1      GOF2\n1 1 0.3382331 0.3871096\n2 2 0.4844901 0.5545014\n3 3 0.6217365 0.7115806\n4 4 0.7284408 0.8337043\n5 5 0.7849281 0.8983543\n\n# Make scree plot\nplot(GOF2 ~ k, data = scree, # Plot stress against k\n     type = 'b', # Lines and points\n     pch = 16, # Point 16 (filled circle)\n     ylab = 'Goodness of Fit', ylim = c(0.3, 1))\npoints(GOF1 ~ k, data = scree, type = 'b', pch = 16, col = 'red') # Add second GOF value\nabline(h = 0.1, lty = 'dashed') # Plot a dashed line at 0.1\nlegend('topleft', pch = 16, legend = c('GOF1', 'GOF2'), col = c('red', 'black')) # Add legend\n\n\n\n\nGoodness of fit scales linearly, so what k to use is more of a judgement call.\n\n# run metric MDS\nmds3 = cmdscale(dist, k=4, eig = T)\nmds3\n\n$points\n             [,1]       [,2]       [,3]       [,4]\nind1   5.84977914  2.7981654  1.2685787 -0.6738375\nind2  -7.46899061 -0.4452479  2.6496404  2.1091477\nind3  -7.87360160  2.4742095  3.4326421  1.2339175\nind4   6.04970828 -1.1964346 -0.9306802 -1.2319775\nind5  -6.77887791  2.8518073 -1.2465315  2.3989342\nind6  -7.21161499  3.9150940 -1.9699687 -2.4369605\nind7   4.79289905 -0.9896933 -2.7067201 -0.2043847\nind8  -2.46317365 -5.3304368 -9.4034890  2.0126521\nind9  -1.86216019 -9.7770302  5.2905629 -1.1532342\nind10  5.45394235  1.1317599  0.3565324  4.1657272\nind11  5.27120921 -0.1097836  4.1678975  1.4238728\nind12  6.20052885  3.6063451 -0.2995254  1.5298300\nind13  0.04035206  1.0712450 -0.6089393 -9.1736869\n\n$eig\n [1]  4.150450e+02  1.794715e+02  1.684147e+02  1.309366e+02  6.931537e+01\n [6]  5.811388e+01  3.306204e+01  1.780496e+01 -4.263256e-14 -8.643935e+00\n[11] -2.208342e+01 -4.468321e+01 -7.952271e+01\n\n$x\nNULL\n\n$ac\n[1] 0\n\n$GOF\n[1] 0.7284408 0.8337043\n\n\nLet’s plot the first two dimensions:\n\n# Plot metric MDS\nplot(mds3$points[,1], mds3$points[,2], # MDS dimension 1 and 2 values\n     type = 'n', # Don't plot any points\n     xlab = 'Dim 1', ylab = 'Dim 2', main = 'Metric MDS') # Labelling\n\n# Plot individual names\ntext(mds3$points[,1], # Add random values pulled from a \n     mds3$points[,2], # normal distribution with mean 0, sd 0.2\n     rownames(data), # Add names\n     col = ifelse(ad == 0, 'purple', 'orange')) # color \n# Add a legend\nlegend('bottomright', legend = c('Juvenile', 'Adult'), fill = c('purple', 'orange'))\n\n\n\n\n\n\n3.4.3 3D Plotting (Optional)\nIt may not be necessary, but if your MDS has more than 2 dimensions, you can try plotting it in three dimensions and see if it helps:\n\nlibrary(plot3D)\n\n# Prepare data to plot\nx = mds3$points[,1]\ny = mds3$points[,2]\nz = mds3$points[,3]\n\n# Create 3D plot\nscatter3D(x,y,z, colvar = NULL, col = 'blue', \n          pch = 16, cex = 0.5, bty = 'g', theta = 5)\n\n# Add text\ntext3D(x, \n       # Add some jiggle to the labels\n       y+rnorm(13, mean = 0, sd = 0.5), z + rnorm(13, mean = 0, sd = 0.5), \n                    labels = names(mds3$points[,1]), add = T, colkey = F, \n                    cex = 0.5, adj = 1, d = 2)"
  },
  {
    "objectID": "a1c.html#mantel-test-graduate-students-only",
    "href": "a1c.html#mantel-test-graduate-students-only",
    "title": "3  Assignment 1c: Cluster Analysis and Multidimensional Scaling",
    "section": "3.5 Mantel Test (Graduate Students Only)",
    "text": "3.5 Mantel Test (Graduate Students Only)\nWe can infer to some extent whether juveniles and adults preferentially associate with each other from our colored MDS plots, but we can also test it statistically using a Mantel test. To run the Mantel test, we need to convert our adult index into a dist object:\n\n# Create dist matrix for adults\nad_dist = dist(ad)\nad_dist\n\n   1 2 3 4 5 6 7 8 9 10 11 12\n2  0                         \n3  0 0                       \n4  0 0 0                     \n5  0 0 0 0                   \n6  1 1 1 1 1                 \n7  1 1 1 1 1 0               \n8  1 1 1 1 1 0 0             \n9  1 1 1 1 1 0 0 0           \n10 0 0 0 0 0 1 1 1 1         \n11 0 0 0 0 0 1 1 1 1  0      \n12 0 0 0 0 0 1 1 1 1  0  0   \n13 0 0 0 0 0 1 1 1 1  0  0  0\n\n\nNote this is dissimilarity: adult-juvenile pairs are assigned 1, and same-class pairs are assigned 0.\nThe Mantel test looks for correlation between this matrix and our original dissociation matrix, and statistically tests if the associations are different from what we would expect due to chance.\n\n# Run mantel test\nlibrary(ade4)\nmantel.rtest(ad_dist, dist, nrepet = 999)\n\nWarning in is.euclid(m1): Zero distance(s)\n\n\nWarning in is.euclid(m2): Zero distance(s)\n\n\nMonte-Carlo test\nCall: mantelnoneuclid(m1 = m1, m2 = m2, nrepet = nrepet)\n\nObservation: 0.1686576 \n\nBased on 999 replicates\nSimulated p-value: 0.073 \nAlternative hypothesis: greater \n\n     Std.Obs  Expectation     Variance \n 1.369210491 -0.001062026  0.015364686 \n\n\nIt’s very close, but we don’t have statistically significant evidence that juveniles and adults associate preferentially with each other in this case."
  },
  {
    "objectID": "a1c.html#tips-for-your-assignment",
    "href": "a1c.html#tips-for-your-assignment",
    "title": "3  Assignment 1c: Cluster Analysis and Multidimensional Scaling",
    "section": "3.6 Tips for your Assignment:",
    "text": "3.6 Tips for your Assignment:\nSome things you may want to think about for your assignment:\n1. How would you pick which cluster analyses and MDS analyses are best for your data? Are they conceptual, or do they have to do with the results? Do they agree?\n2. How would you interpret your statistical results biologically? You don’t have to be right, but don’t be vague, and don’t contradict your results."
  },
  {
    "objectID": "guidelines.html#general-advice",
    "href": "guidelines.html#general-advice",
    "title": "Assignment Guidelines",
    "section": "General Advice",
    "text": "General Advice\n1. Read the grading rubric!\n\nIt is quite objective. There is little latitude for part marks if you are missing parts that you need.\n\n2. You don’t need to tell me the statistical theory or background (unless it’s relevant to your answers)\n\nAll you have to do is answer the questions in the assignment. Anything you write outside of that is just eating up your page limit.\n\n3. Put your biological interpretations together at the end\n\nYour interpretations are more likely to make sense and easier to mark if you put them at the end, and include all of your results together in them rather than inserting them throughout piecemeal.\nAlso, make sure your biological interpretations are consistent with your data/results! They don’t have to be correct, but they have to match your data.\n\n4. Make sure your figures are readable\n\nI can’t tell if your interpretation of your figures is correct if I can’t interpret your figures.\nAlltext on figures should be readable.\nIf you use color, make sure that the colors you use are clearly distinguishable.\n\n5. You’re not alone!\n\nIf you have questions, come to the drop-in sessions, read the discussion boards, or email me to ask questions or set up a meeting if those don’t work for you.\nDo the first two even if you don’t have questions: You may find the answer to questions you didn’t know you had.\nYou’re also welcome to ask questions after an assignment if you want to know why you were graded the way you were, or if you have questions about the comments provided or what you may have done wrong.\n\n6. Ask if you need an extension\n\nWe’re pretty reasonable."
  },
  {
    "objectID": "guidelines.html#submission-formatting",
    "href": "guidelines.html#submission-formatting",
    "title": "Assignment Guidelines",
    "section": "Submission Formatting",
    "text": "Submission Formatting\nHere are some guidelines on how to submit your assignment to make my life easier. You won’t lose marks for not following them, but I would greatly appreciate it if you did.\n1. Hand in your assignment in 3 parts:\n\nYour assignment text\n\n\nAll assignment 1s have a 2 page limit. Put all your text first, with figures and tables together separately at the end. It is easier for me to tell how many pages you wrote this way. You’re not going to lose marks if you’re slightly over (this is not a writing class), if you’re going to lose marks for writing too many pages I’m going to be able to tell anyways.\nShould be a doc or PDF file so I can open it in BrightSpace. Doesn’t matter if it’s produced through word, markdown, etc, as long as it’s in one of those two formats.\n\nb) Your script, submitted as a .txt file\n\nSubmitting as a .txt file allows me to open the script in BrightSpace rather than having to download it if it’s a .R file. It is much more difficult for me to run your script should I need to if you paste it in your assignment document.\n\nc) The data you read into your script\n\nThis is just to make it easy for me to run your script if I think there is a mistake.\n\n2. Don’t put your name on your assignments, in your scripts, or in any of your file names\n\nThe BrightSpace system is anonymous so I mark your assignments blind. That doesn’t work if you write your name.\nDelete your file paths in your script for submission if they have your name in them.\nYou do need to put your B0 number, data code number, and whether you’re a graduate student or an undergraduate student.\n\n3. Follow the assignment guide\n\nYou don’t have to follow this guide to get full marks on the assignments (as always, there are many correct answers when it comes to coding). That said, it’s easier for me to follow what you’re doing if you’re doing the same thing as everyone else.\nIt’s OK to do your own thing, but if you make a mistake, its going to be much harder for me to help you out, and it’s going to take significantly more effort on my end to mark."
  }
]