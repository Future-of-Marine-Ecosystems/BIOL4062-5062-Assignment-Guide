{
  "hash": "0244629ccdc4ee200056440d55817d5b",
  "result": {
    "markdown": "# **Assignment 1e:** Bayesian Data Analysis\n\nAssignment 1e is an introduction Bayesian data analysis, using Bayesian general linear models.\n\nFor this tutorial, we'll be using `cuse.csv` .\n\n## Looking at the Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load in data\ndata = read.csv('cuse.csv')\n\n# Look at the data structure\nhead(data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  X   age education wantsMore notUsing using\n1 1   <25       low       yes       53     6\n2 2   <25       low        no       10     4\n3 3   <25      high       yes      212    52\n4 4   <25      high        no       50    10\n5 5 25-29       low       yes       60    14\n6 6 25-29       low        no       19    10\n```\n:::\n\n```{.r .cell-code}\ndim(data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 16  6\n```\n:::\n:::\n\n\nOur data contains 16 observations of 5 variables - a binomial matrix of how many women are using or not using birth control within 16 groups, and three categorical predictors - age, expressed as a bin, education, and whether they want more children. The first column is a duplicate of our row names. We can get rid of that:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Remove column 1\ndata = data[,-1]\nhead(data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    age education wantsMore notUsing using\n1   <25       low       yes       53     6\n2   <25       low        no       10     4\n3   <25      high       yes      212    52\n4   <25      high        no       50    10\n5 25-29       low       yes       60    14\n6 25-29       low        no       19    10\n```\n:::\n:::\n\n\n## Binomial GLM\n\nBinomial general linear models are used to calculate the probability of a binomial response - in this case, whether someone is using or not using birth control. Binomial GLM response can be fed in either as a true/false set, or as a matrix of successes and failures. According to `?family`, we need to feed in the data with successes first and failures second. Let's create the matrix:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# create response matrix\nresp = cbind(data$using, data$notUsing)\nhead(resp)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     [,1] [,2]\n[1,]    6   53\n[2,]    4   10\n[3,]   52  212\n[4,]   10   50\n[5,]   14   60\n[6,]   10   19\n```\n:::\n:::\n\n\nIn this case, all of our variables are categorical, and they are currently stored as characters:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Check predictor classes\nclass(data$age)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"character\"\n```\n:::\n\n```{.r .cell-code}\nclass(data$education)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"character\"\n```\n:::\n\n```{.r .cell-code}\nclass(data$wantsMore)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"character\"\n```\n:::\n:::\n\n\nThese should function fine as categorical variables. Let's make our GLM:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Run GLM\nm1 = glm(resp ~ age + education + wantsMore, family = 'binomial', data = data)\nsummary(m1) # Summary\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = resp ~ age + education + wantsMore, family = \"binomial\", \n    data = data)\n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)   -0.8082     0.1590  -5.083 3.71e-07 ***\nage25-29       0.3894     0.1759   2.214  0.02681 *  \nage30-39       0.9086     0.1646   5.519 3.40e-08 ***\nage40-49       1.1892     0.2144   5.546 2.92e-08 ***\neducationlow  -0.3250     0.1240  -2.620  0.00879 ** \nwantsMoreyes  -0.8330     0.1175  -7.091 1.33e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 165.772  on 15  degrees of freedom\nResidual deviance:  29.917  on 10  degrees of freedom\nAIC: 113.43\n\nNumber of Fisher Scoring iterations: 4\n```\n:::\n:::\n\n\nIn our summary we see we have 5 predictors: The age bin, low education, and wanting more kids. High education and not wanting more kids are missing because these variables are binary, so we only need one variable to differentiate them. We can also see the values of our model coefficients, their standard errors, and the model AIC.\n\n## Making it Bayesian\n\nThe default GLM function is frequentist (that's why we have p-values). Now lets try a Bayesian approach:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Stan\nlibrary(rstanarm)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: Rcpp\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThis is rstanarm version 2.32.1\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n- See https://mc-stan.org/rstanarm/articles/priors for changes to default priors!\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n- Default priors may change, so it's safest to specify priors, even if equivalent to the defaults.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n- For execution on a local, multicore CPU with excess RAM we recommend calling\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n  options(mc.cores = parallel::detectCores())\n```\n:::\n\n```{.r .cell-code}\nlibrary(bayesplot)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nThis is bayesplot version 1.11.1\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n- Online documentation and vignettes at mc-stan.org/bayesplot\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n- bayesplot theme set to bayesplot::theme_default()\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n   * Does _not_ affect other ggplot2 plots\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n   * See ?bayesplot_theme_set for details on theme setting\n```\n:::\n\n```{.r .cell-code}\nlibrary(shinystan)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: shiny\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nThis is shinystan version 2.6.0\n```\n:::\n\n```{.r .cell-code}\nlibrary(ggplot2)\n\n# Run glm\nm2 = stan_glm(resp ~ age + education + wantsMore, family = 'binomial', data = data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nSAMPLING FOR MODEL 'binomial' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 0.000118 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 1.18 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.153 seconds (Warm-up)\nChain 1:                0.151 seconds (Sampling)\nChain 1:                0.304 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'binomial' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 1.7e-05 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.17 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 0.147 seconds (Warm-up)\nChain 2:                0.156 seconds (Sampling)\nChain 2:                0.303 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'binomial' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 1.8e-05 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.18 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 0.158 seconds (Warm-up)\nChain 3:                0.145 seconds (Sampling)\nChain 3:                0.303 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'binomial' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 2.1e-05 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.21 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 0.151 seconds (Warm-up)\nChain 4:                0.157 seconds (Sampling)\nChain 4:                0.308 seconds (Total)\nChain 4: \n```\n:::\n\n```{.r .cell-code}\nsummary(m2) # Summary\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nModel Info:\n function:     stan_glm\n family:       binomial [logit]\n formula:      resp ~ age + education + wantsMore\n algorithm:    sampling\n sample:       4000 (posterior sample size)\n priors:       see help('prior_summary')\n observations: 16\n predictors:   6\n\nEstimates:\n               mean   sd   10%   50%   90%\n(Intercept)  -0.8    0.2 -1.0  -0.8  -0.6 \nage25-29      0.4    0.2  0.2   0.4   0.6 \nage30-39      0.9    0.2  0.7   0.9   1.1 \nage40-49      1.2    0.2  0.9   1.2   1.5 \neducationlow -0.3    0.1 -0.5  -0.3  -0.2 \nwantsMoreyes -0.8    0.1 -1.0  -0.8  -0.7 \n\nFit Diagnostics:\n           mean   sd   10%   50%   90%\nmean_PPD 31.7    1.6 29.6  31.7  33.8 \n\nThe mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).\n\nMCMC diagnostics\n              mcse Rhat n_eff\n(Intercept)   0.0  1.0  2127 \nage25-29      0.0  1.0  2358 \nage30-39      0.0  1.0  2176 \nage40-49      0.0  1.0  2086 \neducationlow  0.0  1.0  3176 \nwantsMoreyes  0.0  1.0  3310 \nmean_PPD      0.0  1.0  4075 \nlog-posterior 0.0  1.0  1993 \n\nFor each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\n```\n:::\n:::\n\n\nThe `stan_glm` function automatically feeds our model into Stan, which is a Hamiltonian Markov Chain Monte Carlo (MCMC) sampler. Running `summary` on our model gives us some model diagnostics - all our Rhat values are 1 and all our n_eff values are well into the thousands, both of which are a good sign. We can also do some visual checks and tests:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Trace plot\nplot(m2, 'trace')\n```\n\n::: {.cell-output-display}\n![](a1e_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\nThese are trace plots, which show us the parameter values selected for each iteration of the MCMC chain. We want these to look \"fuzzy\" - that indicates the sampler is exploring the full range of possible values. If these lines were to be flat, that would indicate the sampler got \"stuck\" and didn't sample the full posterior distributions. These look good.\n\nLets look at our posteriors:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Plot parameter values with uncertainties\nplot(m2, prob_outer = 0.95)\n```\n\n::: {.cell-output-display}\n![](a1e_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Plot posterior distributions\nplot(m2, 'mcmc_hist')\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![](a1e_files/figure-html/unnamed-chunk-8-2.png){width=672}\n:::\n:::\n\n\nThese plots both give us an idea of our parameter values and their posterior distributions. The former plot shows the median parameter estimates (circle), their 50% quantiles (dark blue box), and their 95% quantiles (thin blue line). The latter shows histograms of the posterior distributions of each of our parameters.\n\nWe can also pull out our coefficients and posteriors directly\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Model coefficients\nm2$coefficients\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n (Intercept)     age25-29     age30-39     age40-49 educationlow wantsMoreyes \n  -0.8090834    0.3881481    0.9127747    1.1921744   -0.3264688   -0.8373483 \n```\n:::\n\n```{.r .cell-code}\n# Model posteriors\nposterior <- as.matrix(m2)\n\n# Plot model posteriors (95% quantile)\nplot_title <- ggtitle(\"Posterior distributions with medians and 95% credible intervals\")\n\nmcmc_areas(posterior, pars = names(m2$coefficients),\n           prob = 0.95) + plot_title\n```\n\n::: {.cell-output-display}\n![](a1e_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\nHow would you interpret these plots?\n\n## Adding Priors\n\nLets try adding some priors:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Run glm with priors\nm3 = stan_glm(resp ~ age + education + wantsMore, family = 'binomial', data = data,\n              prior = normal(location = c(0.2, 1.5, 2, -1, -0.25), # Normal priors, means\n                             scale = c(0.03, 0.03, 0.03, 0.03, 0.03))) # And standard deviations\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nSAMPLING FOR MODEL 'binomial' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 4.1e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.41 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.243 seconds (Warm-up)\nChain 1:                0.113 seconds (Sampling)\nChain 1:                0.356 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'binomial' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 1.7e-05 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.17 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 0.224 seconds (Warm-up)\nChain 2:                0.106 seconds (Sampling)\nChain 2:                0.33 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'binomial' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 2.8e-05 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.28 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 0.201 seconds (Warm-up)\nChain 3:                0.114 seconds (Sampling)\nChain 3:                0.315 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'binomial' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 1.8e-05 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.18 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 0.214 seconds (Warm-up)\nChain 4:                0.129 seconds (Sampling)\nChain 4:                0.343 seconds (Total)\nChain 4: \n```\n:::\n\n```{.r .cell-code}\nsummary(m3) # Summary\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nModel Info:\n function:     stan_glm\n family:       binomial [logit]\n formula:      resp ~ age + education + wantsMore\n algorithm:    sampling\n sample:       4000 (posterior sample size)\n priors:       see help('prior_summary')\n observations: 16\n predictors:   6\n\nEstimates:\n               mean   sd   10%   50%   90%\n(Intercept)  -1.2    0.1 -1.3  -1.2  -1.1 \nage25-29      0.2    0.0  0.2   0.2   0.3 \nage30-39      1.5    0.0  1.4   1.5   1.5 \nage40-49      2.0    0.0  2.0   2.0   2.0 \neducationlow -1.0    0.0 -1.0  -1.0  -0.9 \nwantsMoreyes -0.3    0.0 -0.3  -0.3  -0.2 \n\nFit Diagnostics:\n           mean   sd   10%   50%   90%\nmean_PPD 31.7    1.5 29.8  31.8  33.8 \n\nThe mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).\n\nMCMC diagnostics\n              mcse Rhat n_eff\n(Intercept)   0.0  1.0  6014 \nage25-29      0.0  1.0  6066 \nage30-39      0.0  1.0  6159 \nage40-49      0.0  1.0  6568 \neducationlow  0.0  1.0  6899 \nwantsMoreyes  0.0  1.0  6404 \nmean_PPD      0.0  1.0  4811 \nlog-posterior 0.0  1.0  1690 \n\nFor each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\n```\n:::\n:::\n\n\nLets look at our plots again:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Trace plot\nplot(m3, 'trace')\n```\n\n::: {.cell-output-display}\n![](a1e_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Plot parameter values with uncertainties\nplot(m3, prob_outer = 0.95)\n```\n\n::: {.cell-output-display}\n![](a1e_files/figure-html/unnamed-chunk-11-2.png){width=672}\n:::\n\n```{.r .cell-code}\n# Plot posterior distributions\nplot(m3, 'mcmc_hist')\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![](a1e_files/figure-html/unnamed-chunk-11-3.png){width=672}\n:::\n\n```{.r .cell-code}\n# Model coefficients\nm3$coefficients\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n (Intercept)     age25-29     age30-39     age40-49 educationlow wantsMoreyes \n  -1.1980341    0.2201313    1.4813526    1.9956072   -0.9704883   -0.2822287 \n```\n:::\n\n```{.r .cell-code}\n# Model posteriors\nposterior <- as.matrix(m3)\n\n# Plot model posteriors (95% quantile)\nplot_title <- ggtitle(\"Posterior distributions with medians and 95% credible intervals\")\n\nmcmc_areas(posterior, pars = names(m3$coefficients),\n           prob = 0.95) + plot_title\n```\n\n::: {.cell-output-display}\n![](a1e_files/figure-html/unnamed-chunk-11-4.png){width=672}\n:::\n:::\n\n\nYou can also look at all of your Stan model results using `shinystan` by running `launch_shinystan(model)`. Try it out on your end (it doesn't work in markdown)\n\n## Tips for your Assignment:\n\nSome things you may want to think about for your assignment:\n\n1.  How do the results of these three models differ? Why or why not?\n\n2.  Do you believe certain models are more or less correct? Why or why not?\n\n3.  How would you interpret your statistical results biologically? You don't have to be right, but don't be vague, and don't contradict your results.\n",
    "supporting": [
      "a1e_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}