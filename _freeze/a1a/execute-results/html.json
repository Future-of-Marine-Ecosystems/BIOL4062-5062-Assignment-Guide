{
  "hash": "90d9a24469912ad8f87d24a08baa3a9e",
  "result": {
    "engine": "knitr",
    "markdown": "# **Assignment 1a:** Principal Components Analysis\n\nAssignment 1a focuses on Principal Components Analysis (PCA). Think of PCA as a method of finding associations between data series.\n\nFor this tutorial, we're going to use the dataset in `fishcatch.csv`.\n\n## Looking at the Data\n\nWith any data analysis, step 1 is always to look at your data:\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load in data\ndata = read.csv('fishcatch.csv')\n\n# View data structure\nhead(data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Hauls mackerel bluefin sardine squid limpet\n1     1    1.851   55.60   0.058  6.00 0.0004\n2     2    1.925    1.20   0.252  0.08 0.0027\n3     3    2.506    1.56   0.133  0.06 0.0015\n4     4    1.537   30.00   0.064  9.35 0.0013\n5     5    1.795    0.04   0.086  4.70 0.0022\n6     6    3.371   45.00   0.078  7.66 0.0006\n```\n\n\n:::\n\n```{.r .cell-code}\ndim(data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 25  6\n```\n\n\n:::\n:::\n\n\n\n\n\n\nOur data is a 25 row, 6 column data frame, describing catch of 5 different fisheries species (columns 2-6) caught across 25 hauls (column 1). We want to know if certain species are associated with each other. Lets look a little deeper at the data:\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Generate boxplots\nboxplot(data[,-1]) # Exclude haul\n```\n\n::: {.cell-output-display}\n![](a1a_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# look at data distribution\n# par(mfrow = c(3,2)) # 1 column 5 row grid plot\nhist(data$mackerel, breaks = 10)\n```\n\n::: {.cell-output-display}\n![](a1a_files/figure-html/unnamed-chunk-2-2.png){width=672}\n:::\n\n```{.r .cell-code}\nhist(data$bluefin, breaks = 10)\n```\n\n::: {.cell-output-display}\n![](a1a_files/figure-html/unnamed-chunk-2-3.png){width=672}\n:::\n\n```{.r .cell-code}\nhist(data$sardine, breaks = 10)\n```\n\n::: {.cell-output-display}\n![](a1a_files/figure-html/unnamed-chunk-2-4.png){width=672}\n:::\n\n```{.r .cell-code}\nhist(data$squid, breaks = 10)\n```\n\n::: {.cell-output-display}\n![](a1a_files/figure-html/unnamed-chunk-2-5.png){width=672}\n:::\n\n```{.r .cell-code}\nhist(data$limpet, breaks = 10)\n```\n\n::: {.cell-output-display}\n![](a1a_files/figure-html/unnamed-chunk-2-6.png){width=672}\n:::\n:::\n\n\n\n\n\n\nA few things are immediately obvious from looking at our data:\n\n1\\. There are some large outliers\n\n2\\. The data scales vary greatly across species\n\n3\\. The species all have relatively different distributions, none of which look normal.\n\nAre these issues? How do we fix them?\n\n## Transformations\n\nLook back at the PCA lecture. What are potential problems with PCA?\n\n1\\. Covariance Matrix PCA requires data to be in the same units\n\n2\\. Normality is desirable, but not essential\n\n3\\. Precision is desireable, but not essential\n\n4\\. Many zeroes in the data\n\nWe can fix issue 1 by logging our data:\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create a new data object so we can log the data\ndata_log = data\n\n# Log data\ndata_log[,-1] = log(data_log[,-1]) # Remember to exclude haul\n```\n:::\n\n\n\n\n\n\nNow that we've transformed the data, let's check for normality again:\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Generate histograms\n# par(mfrow = c(3,2)) # 1 column 5 row grid plot\nhist(data_log$mackerel, breaks = 10)\n```\n\n::: {.cell-output-display}\n![](a1a_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n\n```{.r .cell-code}\nhist(data_log$bluefin, breaks = 10)\n```\n\n::: {.cell-output-display}\n![](a1a_files/figure-html/unnamed-chunk-4-2.png){width=672}\n:::\n\n```{.r .cell-code}\nhist(data_log$sardine, breaks = 10)\n```\n\n::: {.cell-output-display}\n![](a1a_files/figure-html/unnamed-chunk-4-3.png){width=672}\n:::\n\n```{.r .cell-code}\nhist(data_log$squid, breaks = 10)\n```\n\n::: {.cell-output-display}\n![](a1a_files/figure-html/unnamed-chunk-4-4.png){width=672}\n:::\n\n```{.r .cell-code}\nhist(data_log$limpet, breaks = 10)\n```\n\n::: {.cell-output-display}\n![](a1a_files/figure-html/unnamed-chunk-4-5.png){width=672}\n:::\n:::\n\n\n\n\n\n\nThese look much better. We can also confirm this statistically:\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Generate histograms\nshapiro.test(data_log$mackerel)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  data_log$mackerel\nW = 0.9425, p-value = 0.1691\n```\n\n\n:::\n\n```{.r .cell-code}\nshapiro.test(data_log$bluefin)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  data_log$bluefin\nW = 0.98186, p-value = 0.9193\n```\n\n\n:::\n\n```{.r .cell-code}\nshapiro.test(data_log$sardine)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  data_log$sardine\nW = 0.94113, p-value = 0.1572\n```\n\n\n:::\n\n```{.r .cell-code}\nshapiro.test(data_log$squid)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  data_log$squid\nW = 0.96226, p-value = 0.4613\n```\n\n\n:::\n\n```{.r .cell-code}\nshapiro.test(data_log$limpet)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  data_log$limpet\nW = 0.96437, p-value = 0.5082\n```\n\n\n:::\n:::\n\n\n\n\n\n\nAll 5 species fail to reject the null hypothesis that the data are normally distributed. Logging the data also helps deal with the outliers:\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Generate boxplots\nboxplot(data_log[,-1])\n```\n\n::: {.cell-output-display}\n![](a1a_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\nNote that we can only log the data if there are no zeroes:\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Generate test data\ndata_test = data; data_test[1,6] = 0 # Change the first limpet value to 0\n\n# Try to log the data\ndata_test[1,] # Print first row\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Hauls mackerel bluefin sardine squid limpet\n1     1    1.851    55.6   0.058     6      0\n```\n\n\n:::\n\n```{.r .cell-code}\nlog(data_test[,-1])[1,] # Print logs of the first row\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  mackerel  bluefin   sardine    squid limpet\n1 0.615726 4.018183 -2.847312 1.791759   -Inf\n```\n\n\n:::\n:::\n\n\n\n\n\n\nlog(0) returnes negative infinity. That's going to be a problem later in our analysis. We can fix that by adding a small increment before taking the log. Keep in mind though that each species has a different magnitude in this dataset, and adding an inappropriate increment could cause us trouble later:\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Test boxplots of different increments\nboxplot(log(data_test$limpet), # Warning because of -Inf\n        log(data_test$limpet + 1),\n        log(data_test$limpet + 0.001),\n        log(data_test$limpet + 0.000000001))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in bplt(at[i], wid = width[i], stats = z$stats[, i], out =\nz$out[z$group == : Outlier (-Inf) in boxplot 1 is not drawn\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](a1a_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\nIf the increment is too big, we eliminate the variance in our data. If the increment is to small, we create an outlier.\n\n## Running PCA\n\nNow that we've checked and transformed our data, we're ready to run PCA. There are two kinds of PCA: We can run PCA on the Covariance Matrix, or the Correlation Matrix.\n\n### Covariance Matrix\n\nWe can run PCA on the covariance matrix as follows:\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Run PCA - Covariance\npca_1 = princomp(data_log[,-1]) # We don't want haul in our PCA!\nsummary(pca_1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nImportance of components:\n                          Comp.1    Comp.2    Comp.3     Comp.4      Comp.5\nStandard deviation     2.8055354 1.3857803 1.3351790 0.55247629 0.182937780\nProportion of Variance 0.6607195 0.1612035 0.1496458 0.02562199 0.002809263\nCumulative Proportion  0.6607195 0.8219229 0.9715687 0.99719074 1.000000000\n```\n\n\n:::\n:::\n\n\n\n\n\n\nRunning a summary on our PCA gives us the standard deviation of each principal component, the proportion of variance explained by each principal component, and the cumulative variance explained as we add each component.\n\nEach principal component is an **eigenvector** of the correlation/covariance matrix (remember from lecture that the *j*th principal component is the *j*th eigenvector of the correlation/covariance matrix). The **eigenvalues** are the variance of each individual principal component. The principal components are organized by their eigenvalues - the first principal component is the eigenvector with the largest eigenvalue, the second principal component is the eigenvector with the second largest eigenvalue, and so on.\n\nThe `princomp()` function gives us the standard deviation of each principal component; We can square these to get the eigenvalues:\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate and pring eigenvalues\neigenvalues = pca_1$sdev^2\neigenvalues\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    Comp.1     Comp.2     Comp.3     Comp.4     Comp.5 \n7.87102905 1.92038712 1.78270294 0.30523005 0.03346623 \n```\n\n\n:::\n:::\n\n\n\n\n\n\nWe can use the eigenvalues to reproduce the reset of the `princomp()` output. The proportion of variance is the value of each eigenvalue divided by the sum of all the eigenvalues. The cumulative proportion is the cumulative sum of the proportions of variance. Since there are 5 components, the cumulative proportion of component 5 is 1 (i.e. all of the variance).\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate and print proportion of variance\nprop_var = eigenvalues/sum(eigenvalues); prop_var\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     Comp.1      Comp.2      Comp.3      Comp.4      Comp.5 \n0.660719468 0.161203465 0.149645813 0.025621991 0.002809263 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Calculate cumulative proportion of variance\ncum_prop = cumsum(prop_var); cum_prop\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Comp.1    Comp.2    Comp.3    Comp.4    Comp.5 \n0.6607195 0.8219229 0.9715687 0.9971907 1.0000000 \n```\n\n\n:::\n:::\n\n\n\n\n\n\nHere, we see the first principal component explains 66% of the variance. The second explains 16%, which adds up to 82% with the first component, and so on up to component 5. We can visualize the cumulative variance explained with a scree plot:\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Generate scree plot\nplot(pca_1, type = 'l') # Scree is built into the plot for PCA\n```\n\n::: {.cell-output-display}\n![](a1a_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\nWe see most of the variance is explained by component 1, then a similar lesser amount is explained by 2 and 3, followed by another drop to 4 and 5.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Print loadings\nprint(loadings(pca_1),cutoff=0.00) #all loadings!\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nLoadings:\n         Comp.1 Comp.2 Comp.3 Comp.4 Comp.5\nmackerel  0.018  0.294  0.047  0.527  0.796\nbluefin  -0.654  0.136  0.739 -0.089 -0.020\nsardine   0.060  0.626 -0.015  0.520 -0.577\nsquid    -0.745  0.049 -0.664  0.029  0.018\nlimpet    0.116  0.707 -0.102 -0.665  0.183\n\n               Comp.1 Comp.2 Comp.3 Comp.4 Comp.5\nSS loadings       1.0    1.0    1.0    1.0    1.0\nProportion Var    0.2    0.2    0.2    0.2    0.2\nCumulative Var    0.2    0.4    0.6    0.8    1.0\n```\n\n\n:::\n:::\n\n\n\n\n\n\nThe PCA loadings are the correlations between the variables and each component. Here, we see bluefin and squid are strongly negatively correlated with component 1, while mackerel, sardine, and limpet are weakly positively correlated with component 1. We can continue this type of interpretation through the other components as well.\n\nOur PCA object also contains the PCA scores for each individual data point:\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Print PCA scores\nhead(pca_1$scores)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        Comp.1     Comp.2     Comp.3     Comp.4      Comp.5\n[1,] -3.551007 -2.2507718  0.6725187 -0.1223707 -0.06754585\n[2,]  2.484116 -0.6980669  0.4886052 -0.3932653 -0.53609582\n[3,]  2.425206 -1.4149241  0.9556963 -0.2274184 -0.07560834\n[4,] -3.339469 -1.4723306 -0.2089590 -0.8854067 -0.03598265\n[5,]  1.580988 -1.8002844 -4.6958830 -0.4313924  0.13590020\n[6,] -3.519487 -1.6187995  0.3362833  0.1040827  0.32134755\n```\n\n\n:::\n:::\n\n\n\n\n\n\nScores are the value of each data point on each principal component. Lets try plotting them:\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Plot scores - components 1 and 2\nplot(pca_1$scores[,1], # Scores on component 1\n     pca_1$scores[,2], # Scores on component 3\n     pch=16, # Point 16 (colored circle)\n     xlab=\"1st principal component\",ylab=\"2nd principal component\",main=\"Scores plot\") # Axis and plot labels\n```\n\n::: {.cell-output-display}\n![](a1a_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\nThis generates a scatterplot showing us the value of each data point in principal components 1 (x) and 2 (y).\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Plot scores - components 1 and 2\nplot(pca_1$scores[,1], # Scores on component 1\n     pca_1$scores[,2], # Scores on component 3\n     pch=16, # Point 16 (colored circle)\n     xlab=\"1st principal component\",ylab=\"2nd principal component\",main=\"Scores plot\") # Axis and plot labels\n\n# Add loadings to plot\narrows(0,0, # Draw arrows from zero\n       pca_1$loadings[,1], # Draw to PC1 loading in X\n       pca_1$loadings[,2], # Draw to PC2 loading in Y\n       col=\"black\", length = 0.1) # Arrow color and arrowhead length\ntext(pca_1$loadings[,1],pca_1$loadings[,2],names(data_log[,-1]),cex=1.0 ,col=\"black\") # Add text labels for each variable\n```\n\n::: {.cell-output-display}\n![](a1a_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\nThe arrows are a little small, so let's add a scaling factor:\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Plot scores - components 1 and 2\nplot(pca_1$scores[,1], # Scores on component 1\n     pca_1$scores[,2], # Scores on component 3\n     pch=16, # Point 16 (colored circle)\n     xlab=\"1st principal component\",ylab=\"2nd principal component\",main=\"Scores plot\") # Axis and plot labels\n\n# Add loadings to plot\nsf = 3 # Scaling factor\nsft = 3.2 # Scaling factor for text\narrows(0,0, # Draw arrows from zero\n       pca_1$loadings[,1]*sf, # Draw to PC1 * scaling factor loading in X\n       pca_1$loadings[,2]*sf, # Draw to PC2 * scaling factor loading in Y\n       col=\"black\", length = 0.1) # Arrow color and arrowhead length\ntext(pca_1$loadings[,1]*sft,pca_1$loadings[,2]*sft, names(data_log[,-1]), cex=1.0, col=\"black\") # Add text labels for each variable\n```\n\n::: {.cell-output-display}\n![](a1a_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\nWhat about the haul number? Does that have an effect? Let's try adding that on as well:\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create a color palette\ncolfunc = colorRampPalette(c('orangered1', 'turquoise2'))\n\n# Plot scores - components 1 and 2\nplot(pca_1$scores[,1], # Scores on component 1\n     pca_1$scores[,2], # Scores on component 3\n     pch=16, # Point 16 (colored circle)\n     col = colfunc(nrow(pca_1$scores)), # Color points by haul using our color palette\n     xlab=\"1st principal component\",ylab=\"2nd principal component\",main=\"Scores plot\") # Axis and plot labels\n\n# Add loadings to plot\nsf = 3 # Scaling factor\nsft = 3.2 # Scaling factor for text\narrows(0,0, # Draw arrows from zero\n       pca_1$loadings[,1]*sf, # Draw to PC1 * scaling factor loading in X\n       pca_1$loadings[,2]*sf, # Draw to PC2 * scaling factor loading in Y\n       col=\"black\", length = 0.1) # Arrow color and arrowhead length\ntext(pca_1$loadings[,1]*sft,pca_1$loadings[,2]*sft, names(data_log[,-1]), cex=1.0, col=\"black\") # Add text labels for each variable\n```\n\n::: {.cell-output-display}\n![](a1a_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\nSince we used color for haul, we need to add a legend:\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set plot layout\nlayout(matrix(1:2,ncol=2), # 1 row, 2 columns\n       width = c(2,1), # Width\n       height = c(1,1)) # Height\n\n# Create a color palette\ncolfunc = colorRampPalette(c('orangered1', 'turquoise2'))\n\n# Plot scores - components 1 and 2\nplot(pca_1$scores[,1], # Scores on component 1\n     pca_1$scores[,2], # Scores on component 3\n     pch=16, # Point 16 (colored circle)\n     col = colfunc(nrow(pca_1$scores)), # Color points by haul using our color palette\n     xlab=\"1st principal component\",ylab=\"2nd principal component\",main=\"Scores plot\") # Axis and plot labels\n\n# Add loadings to plot\nsf = 3 # Scaling factor\nsft = 3.2 # Scaling factor for text\narrows(0,0, # Draw arrows from zero\n       pca_1$loadings[,1]*sf, # Draw to PC1 * scaling factor loading in X\n       pca_1$loadings[,2]*sf, # Draw to PC2 * scaling factor loading in Y\n       col=\"black\", length = 0.1) # Arrow color and arrowhead length\ntext(pca_1$loadings[,1]*sft,pca_1$loadings[,2]*sft, names(data_log[,-1]), cex=1.0, col=\"black\") # Add text labels for each variable\n\n# Generate legend\nlegend_image <- as.raster(matrix(colfunc(nrow(pca_1$scores)), ncol=1))\nplot(c(0,2),c(0,1),type = 'n', axes = F,xlab = '', ylab = '', main = 'Haul')\ntext(x=1.5, y =seq(0,1,l=5), labels = seq(1,25,l=5))\nrasterImage(legend_image, 0, 0, 1,1)\n```\n\n::: {.cell-output-display}\n![](a1a_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\nNow we have a completed scores plot with loadings arrows. How would you interpret this plot?\n\n### Correlation Matrix\n\nNow let's try the correlation matrix. The correlation matrix performs the same analysis, but on standardized data. The princomp() function does this for us if we set cor = T:\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Run PCA - Correlation\npca_2 = princomp(data_log[,-1], cor = T)\nsummary(pca_2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nImportance of components:\n                         Comp.1    Comp.2     Comp.3     Comp.4     Comp.5\nStandard deviation     1.595782 1.2503536 0.70708572 0.57220519 0.25041296\nProportion of Variance 0.509304 0.3126768 0.09999404 0.06548376 0.01254133\nCumulative Proportion  0.509304 0.8219809 0.92197491 0.98745867 1.00000000\n```\n\n\n:::\n\n```{.r .cell-code}\n# In case you don't believe me, heres the covariance matrix if we pre-standardize the data\npca_test = princomp(scale(data_log[-1]))\nsummary(pca_test)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nImportance of components:\n                         Comp.1    Comp.2     Comp.3     Comp.4     Comp.5\nStandard deviation     1.563541 1.2250914 0.69279969 0.56064429 0.24535359\nProportion of Variance 0.509304 0.3126768 0.09999404 0.06548376 0.01254133\nCumulative Proportion  0.509304 0.8219809 0.92197491 0.98745867 1.00000000\n```\n\n\n:::\n:::\n\n\n\n\n\n\nNow we can go through the same pattern of analyses as we did for covariance:\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Generate scree plot\nplot(pca_2, type = 'l') # Scree is built into the plot for PCA\n```\n\n::: {.cell-output-display}\n![](a1a_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Print loadings\nprint(loadings(pca_2),cutoff=0.00) #all loadings!\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nLoadings:\n         Comp.1 Comp.2 Comp.3 Comp.4 Comp.5\nmackerel  0.524  0.272  0.527  0.297  0.535\nbluefin  -0.198  0.682  0.264 -0.651 -0.050\nsardine   0.591  0.209  0.025  0.109 -0.771\nsquid    -0.233  0.645 -0.472  0.550  0.059\nlimpet    0.532  0.036 -0.655 -0.416  0.338\n\n               Comp.1 Comp.2 Comp.3 Comp.4 Comp.5\nSS loadings       1.0    1.0    1.0    1.0    1.0\nProportion Var    0.2    0.2    0.2    0.2    0.2\nCumulative Var    0.2    0.4    0.6    0.8    1.0\n```\n\n\n:::\n\n```{.r .cell-code}\n# Set plot layout\nlayout(matrix(1:2,ncol=2), # 1 row, 2 columns\n       width = c(2,1), # Width\n       height = c(1,1)) # Height\n\n# Create a color palette\ncolfunc = colorRampPalette(c('orangered1', 'turquoise2'))\n\n# Plot scores - components 1 and 2\nplot(pca_2$scores[,1], # Scores on component 1\n     pca_2$scores[,2], # Scores on component 3\n     pch=16, # Point 16 (colored circle)\n     col = colfunc(nrow(pca_2$scores)), # Color points by haul using our color palette\n     xlab=\"1st principal component\",ylab=\"2nd principal component\",main=\"Scores plot\") # Axis and plot labels\n\n# Add loadings to plot\nsf = 3 # Scaling factor\nsft = 3.2 # Scaling factor for text\narrows(0,0, # Draw arrows from zero\n       pca_2$loadings[,1]*sf, # Draw to PC1 * scaling factor loading in X\n       pca_2$loadings[,2]*sf, # Draw to PC2 * scaling factor loading in Y\n       col=\"black\", length = 0.1) # Arrow color and arrowhead length\ntext(pca_2$loadings[,1]*sft,pca_2$loadings[,2]*sft, names(data_log[,-1]), cex=1.0, col=\"black\") # Add text labels for each variable\n\n# Generate legend\nlegend_image <- as.raster(matrix(colfunc(nrow(pca_2$scores)), ncol=1))\nplot(c(0,2),c(0,1),type = 'n', axes = F,xlab = '', ylab = '', main = 'Haul')\ntext(x=1.5, y =seq(0,1,l=5), labels = seq(1,25,l=5))\nrasterImage(legend_image, 0, 0, 1,1)\n```\n\n::: {.cell-output-display}\n![](a1a_files/figure-html/unnamed-chunk-21-2.png){width=672}\n:::\n:::\n\n\n\n\n\n\nHow would you interpret this plot? Does it differ from the covariance plot?\n\n### Alternative Methods\n\nThere are a few other ways you can generate, and/or plot your PCAs if you prefer.\n\n#### Biplot\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Exploring biplot\nbiplot(pca_1) # Covariance\n```\n\n::: {.cell-output-display}\n![](a1a_files/figure-html/unnamed-chunk-22-1.png){width=672}\n:::\n\n```{.r .cell-code}\nbiplot(pca_2) # Correlation\n```\n\n::: {.cell-output-display}\n![](a1a_files/figure-html/unnamed-chunk-22-2.png){width=672}\n:::\n:::\n\n\n\n\n\n\n#### ggplot\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\n\n# ggplot version - Covariance\n\n# turn PCA scores into data frame\npca_1_plot = data.frame(Haul = data_log$Haul, pca_1$scores) \n\n# Turn PCA loadings into data frame (This gets a little complicated)\npca_1_loadings = as.data.frame(matrix(as.numeric(pca_1$loadings), \n                                      dim(pca_1$loadings)[1], dim(pca_1$loadings)[2]))\ncolnames(pca_1_loadings) = colnames(pca_1_plot)[-1]\n\n# Plot\nggplot(pca_1_plot, aes(x = Comp.1, y = Comp.2, color = Haul)) +\n  \n  # Scores\n  geom_point() + scale_colour_distiller(palette = 15) + \n  \n  # Loadings\n  geom_segment(data = pca_1_loadings, aes(x = 0, y = 0,xend = Comp.1 , yend = Comp.2), \n    arrow = arrow(length = unit(0.3, \"cm\"), type = \"open\", angle = 25), \n    linewidth = 1, color = \"darkblue\") + \n  \n  # Labels\n  geom_text(data = pca_1_loadings, color = 'darkblue', nudge_x = 0.2, nudge_y = 0.2, # Labels\n                aes(x = Comp.1, y = Comp.2, label = colnames(data_log)[-1]))\n```\n\n::: {.cell-output-display}\n![](a1a_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# ggplot version - Correlation\n\n# turn PCA scores into data frame\npca_2_plot = data.frame(Haul = data_log$Haul, pca_2$scores) \n\n# Turn PCA loadings into data frame\npca_2_loadings = as.data.frame(matrix(as.numeric(pca_2$loadings), \n                                      dim(pca_2$loadings)[1], dim(pca_2$loadings)[2]))\ncolnames(pca_2_loadings) = colnames(pca_2_plot)[-1]\n\n# Plot\nggplot(pca_2_plot, aes(x = Comp.1, y = Comp.2, color = Haul)) +\n  \n  # Scores\n  geom_point() + scale_colour_distiller(palette = 15) + \n  \n  # Loadings\n  geom_segment(data = pca_2_loadings, aes(x = 0, y = 0,xend = Comp.1 , yend = Comp.2), \n               arrow = arrow(length = unit(0.3, \"cm\"), type = \"open\", angle = 25), \n               linewidth = 1, color = \"darkblue\") + \n  \n  # Labels\n  geom_text(data = pca_2_loadings, color = 'darkblue', nudge_x = 0.2, nudge_y = 0.2, # Labels\n            aes(x = Comp.1, y = Comp.2, label = colnames(data_log)[-1]))\n```\n\n::: {.cell-output-display}\n![](a1a_files/figure-html/unnamed-chunk-23-2.png){width=672}\n:::\n:::\n\n\n\n\n\n\nYou can also run PCA using the prcomp() function instead of princomp(), setting scale = T if you want the correlation matrix. You can then use autoplot() with the ggfortify package to plot the results.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# ggplot v2\nlibrary(ggfortify)\n\n# Run PCA - Covariance\npca_1a = prcomp(data_log[,-1])\n\n# Run autoplot\nautoplot(pca_1a, data = data_log, color = 'Hauls', loadings = T, loadings.label = T)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: `aes_string()` was deprecated in ggplot2 3.0.0.\nℹ Please use tidy evaluation idioms with `aes()`.\nℹ See also `vignette(\"ggplot2-in-packages\")` for more information.\nℹ The deprecated feature was likely used in the ggfortify package.\n  Please report the issue at <https://github.com/sinhrks/ggfortify/issues>.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](a1a_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Run PCA - Correlation\npca_2a = prcomp(data_log[,-1], scale = T)\n\n# Run autoplot\nautoplot(pca_2a, data = data_log, color = 'Hauls', loadings = T, loadings.label = T)\n```\n\n::: {.cell-output-display}\n![](a1a_files/figure-html/unnamed-chunk-24-2.png){width=672}\n:::\n:::\n\n\n\n\n\n\n## Varimax Rotation (Optional)\n\nVarimax rotation attempts to improve the interpretability of PCA results by lining up loadings with the axes. This can be useful, particularly with large numbers of variables.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Scaling factors\nsf = 2.5\nsft = 2.8\n\n# Varimax rotation - Covariance\nv1 = varimax(pca_1$loadings[,1:2])\nv1_scores = pca_1$scores[,1:2]%*%v1$rotmat\n\n# Plot scores - components 1 and 2\nplot(v1_scores[,1],v1_scores[,2],pch=15, col = colfunc(nrow(v1_scores)),\n     xlab=\"1st varimax component\",ylab=\"2nd varimax component\",main=\"varimax scores plot\")\n\n# Add loadings\narrows(0,0,v1$loadings[,1]*sf,v1$loadings[,2]*sf,col=\"black\")\ntext(v1$loadings[,1]*sft,v1$loadings[,2]*sft,names(data_log[,-1]),asp=1,cex=1.0 ,col=\"black\")\n```\n\n::: {.cell-output-display}\n![](a1a_files/figure-html/unnamed-chunk-25-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Varimax rotation - Correlation\nv2 = varimax(pca_2$loadings[,1:2])\nv2_scores = pca_2$scores[,1:2]%*%v2$rotmat\n\n# Plot scores - components 1 and 2\nplot(v2_scores[,1],v2_scores[,2],pch=15, col = colfunc(nrow(v2_scores)),\n     xlab=\"1st varimax component\",ylab=\"2nd varimax component\",main=\"varimax scores plot\")\n\n# Add loadings\narrows(0,0,v2$loadings[,1]*sf,v2$loadings[,2]*sf,col=\"black\")\ntext(v2$loadings[,1]*sft,v2$loadings[,2]*sft,names(data_log[,-1]),asp=1,cex=1.0 ,col=\"black\")\n```\n\n::: {.cell-output-display}\n![](a1a_files/figure-html/unnamed-chunk-25-2.png){width=672}\n:::\n:::\n\n\n\n\n\n\nNote that it's pretty hard to tell the hauls apart using this color scale. Make sure your plots are always clear and readable.\n\n## Tips for your assignment:\n\nSome things you may want to think about for your assignment:\n\n1\\. Do your covariance and correlation plots differ? Do you think one is better suited to answering your research question? Why? Is your answer conceptual, or does it have to do with the results? Both?\n\n2\\. How would you quantitatively examine the effect of haul on the PCA scores above? Is it associated with any of the principal components?\n\n3\\. How would you interpret your statistical results biologically? You don't have to be right, but don't be vague, and don't contradict your results.\n",
    "supporting": [
      "a1a_files\\figure-html"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}